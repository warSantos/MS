{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/project/.env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sys import path\n",
    "path.append('../utils/')\n",
    "\n",
    "from utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\", \"20ng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spr</th>\n",
       "      <th>kpr</th>\n",
       "      <th>xtr</th>\n",
       "      <th>xfr</th>\n",
       "      <th>stmk</th>\n",
       "      <th>ltmk</th>\n",
       "      <th>lpr</th>\n",
       "      <th>str</th>\n",
       "      <th>ltr</th>\n",
       "      <th>lfr</th>\n",
       "      <th>...</th>\n",
       "      <th>bert</th>\n",
       "      <th>sfr</th>\n",
       "      <th>xtmk</th>\n",
       "      <th>xlnet_softmax</th>\n",
       "      <th>xpr</th>\n",
       "      <th>label</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>docs</th>\n",
       "      <th>conc_size</th>\n",
       "      <th>hit_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is the story of Kent, the archetype Finn,...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In article &lt;16BA7103C3.I3150101@dbstu1.rz.tu-b...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A new alternative to Scouting for those \"unacc...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[reply to zazen@austin.ibm.com (E. H. Welbon)]...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In article &lt;4949@eastman.UUCP&gt; dps@nasa.kodak....</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   spr  kpr  xtr  xfr  stmk  ltmk  lpr  str  ltr  lfr  ...  bert  sfr  xtmk  \\\n",
       "0    0    0    0    0     0     0    0    0    0    0  ...     2    0     0   \n",
       "1    0    0    0    0     0     0    0    0    0    0  ...     0    0     0   \n",
       "2    5   17   18   19    18    18    5   11   11    6  ...     5    6    18   \n",
       "3    0    0    0    0     0     0    0    0    0    0  ...     0    0     0   \n",
       "4    0    0    0    0     0     0    0    0    0    0  ...     0    0     0   \n",
       "\n",
       "   xlnet_softmax  xpr  label  fold_id  \\\n",
       "0              0    0      0        0   \n",
       "1              0    0      0        0   \n",
       "2             13    6      0        0   \n",
       "3              0    5      0        0   \n",
       "4              0    0      0        0   \n",
       "\n",
       "                                                docs  conc_size  hit_counts  \n",
       "0  This is the story of Kent, the archetype Finn,...         18          18  \n",
       "1  In article <16BA7103C3.I3150101@dbstu1.rz.tu-b...         18          18  \n",
       "2  A new alternative to Scouting for those \"unacc...          6           0  \n",
       "3  [reply to zazen@austin.ibm.com (E. H. Welbon)]...         17          17  \n",
       "4  In article <4949@eastman.UUCP> dps@nasa.kodak....         18          18  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_datasets = get_datasets(DATASETS, path=\"/home/welton/data/pd_datasets/__dset__.csv\", sep=';')\n",
    "pd_datasets[\"20ng\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(dataset: str, fold: int, df: pd.DataFrame):\n",
    "    \n",
    "    # Loading the bert fine-tuned model and sending him to GPU.\n",
    "    model_path = f\"/home/welton/data/clfs_output/split_10/{dataset}/10_folds/rep_bert/{fold}/model\"\n",
    "    model = torch.load(model_path).to(device)\n",
    "    # Setting bert to output attention weights.\n",
    "    model.config.output_attentions = True\n",
    "    # Loading bert tokenizer.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    # Transforming the documents in ids.\n",
    "    tokens_ids = tokenizer(df.docs.values.tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(device)\n",
    "    # Reverting ids to tokens.\n",
    "    tokens = [ tokenizer.convert_ids_to_tokens(ids) for ids in tokens_ids.input_ids ]\n",
    "    # Computing attention weights.\n",
    "    output = model.bert(**tokens_ids)\n",
    "    docs_att = output.attentions[-1]\n",
    "    att_weights = []\n",
    "    # Making the mean of the attention on the twelve heads of BERT's last layer.\n",
    "    for doc in docs_att:\n",
    "        mean_att = torch.mean(doc, axis=0)\n",
    "        w = torch.sum(mean_att, axis=0).detach().cpu().numpy()\n",
    "        att_weights.append(w)\n",
    "    return tokens, att_weights\n",
    "\n",
    "def set_word_attention(doc_tokens: list, att: np.ndarray):\n",
    "    wo = []\n",
    "    we = []\n",
    "    for idx, token in enumerate(doc_tokens):\n",
    "        if token not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            wo.append(token)\n",
    "            we.append(att[idx])\n",
    "    return wo, we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WEBKB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.41 GiB (GPU 0; 7.79 GiB total capacity; 4.64 GiB already allocated; 2.34 GiB free; 4.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m tqdm(np\u001b[39m.\u001b[39marange(\u001b[39m10\u001b[39m)):\n\u001b[1;32m      6\u001b[0m     df \u001b[39m=\u001b[39m pd_datasets[dataset]\n\u001b[0;32m----> 7\u001b[0m     tokens, att_weights \u001b[39m=\u001b[39m get_attention(dataset, fold, df[df\u001b[39m.\u001b[39;49mfold_id \u001b[39m==\u001b[39;49m fold])\n\u001b[1;32m      8\u001b[0m     words \u001b[39m=\u001b[39m []; weights \u001b[39m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m dt, da \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tokens, att_weights):\n",
      "Cell \u001b[0;32mIn [5], line 15\u001b[0m, in \u001b[0;36mget_attention\u001b[0;34m(dataset, fold, df)\u001b[0m\n\u001b[1;32m     13\u001b[0m tokens \u001b[39m=\u001b[39m [ tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(ids) \u001b[39mfor\u001b[39;00m ids \u001b[39min\u001b[39;00m tokens_ids\u001b[39m.\u001b[39minput_ids ]\n\u001b[1;32m     14\u001b[0m \u001b[39m# Computing attention weights.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mbert(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokens_ids)\n\u001b[1;32m     16\u001b[0m docs_att \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mattentions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     17\u001b[0m att_weights \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:611\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    602\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    603\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    604\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    612\u001b[0m         hidden_states,\n\u001b[1;32m    613\u001b[0m         attention_mask,\n\u001b[1;32m    614\u001b[0m         layer_head_mask,\n\u001b[1;32m    615\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    616\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    617\u001b[0m         past_key_value,\n\u001b[1;32m    618\u001b[0m         output_attentions,\n\u001b[1;32m    619\u001b[0m     )\n\u001b[1;32m    621\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m    430\u001b[0m         head_mask,\n\u001b[1;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    433\u001b[0m         past_key_value,\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:331\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_layer, value_layer)\n\u001b[1;32m    330\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key_query\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    334\u001b[0m     seq_length \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.41 GiB (GPU 0; 7.79 GiB total capacity; 4.64 GiB already allocated; 2.34 GiB free; 4.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#dataset = \"20ng\"\n",
    "for dataset in DATASETS:\n",
    "    docs_att = []\n",
    "    print(f\"[{dataset.upper()}]\")\n",
    "    for fold in tqdm(np.arange(10)):\n",
    "        df = pd_datasets[dataset]\n",
    "        tokens, att_weights = get_attention(dataset, fold, df[df.fold_id == fold])\n",
    "        words = []; weights = []\n",
    "        for dt, da in zip(tokens, att_weights):\n",
    "            wo, we = set_word_attention(dt, da)\n",
    "            words.append(wo)\n",
    "            weights.append(we)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    data = {\"docs\": words, \"weights\": weights}\n",
    "    att_df = pd.DataFrame(data)\n",
    "    output_dir = f\"/home/welton/data/attention/{dataset}/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    att_df.to_csv(f\"{output_dir}/{dataset}.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 0.5484288],\n",
       " ['is', 0.33609223],\n",
       " ['the', 0.31935322],\n",
       " ['story', 0.9013461],\n",
       " ['of', 0.37335452],\n",
       " ['kent', 3.7715073],\n",
       " [',', 0.5740509],\n",
       " ['the', 0.74913317],\n",
       " ['arch', 0.58199304],\n",
       " ['##ety', 0.9072833],\n",
       " ['##pe', 0.7144489],\n",
       " ['finn', 4.488489],\n",
       " [',', 10.46603],\n",
       " ['that', 0.7912102],\n",
       " ['lives', 0.6414691],\n",
       " ['in', 0.42168948],\n",
       " ['the', 8.845614],\n",
       " ['bay', 2.436592],\n",
       " ['area', 0.8016088],\n",
       " [',', 9.61158],\n",
       " ['and', 0.49231413],\n",
       " ['tried', 0.58744675],\n",
       " ['to', 0.5151708],\n",
       " ['purchase', 0.9629158],\n",
       " ['thomas', 1.3626342],\n",
       " ['pain', 5.010043],\n",
       " ['##e', 1.289026],\n",
       " [\"'\", 0.90068424],\n",
       " ['s', 0.8964683],\n",
       " ['\"', 0.72473943],\n",
       " ['age', 1.1120569],\n",
       " ['of', 0.618949],\n",
       " ['reason', 3.6639862],\n",
       " ['\"', 0.40983197],\n",
       " ['.', 12.495114],\n",
       " ['this', 0.8442351],\n",
       " ['man', 0.9850842],\n",
       " ['was', 0.811539],\n",
       " ['driving', 1.718617],\n",
       " ['around', 1.1216342],\n",
       " [',', 0.2406631],\n",
       " ['to', 0.6028936],\n",
       " ['stacey', 4.0122404],\n",
       " ['##s', 1.1932758],\n",
       " [',', 0.33007967],\n",
       " ['to', 0.93505406],\n",
       " ['books', 2.1772122],\n",
       " ['inc', 2.8864007],\n",
       " [',', 0.1458948],\n",
       " ['to', 0.4601766],\n",
       " ['\"', 0.9301051],\n",
       " ['well', 1.4117259],\n",
       " [',', 0.2864714],\n",
       " ['clean', 0.79535985],\n",
       " ['##light', 1.6739159],\n",
       " ['##ed', 0.36047137],\n",
       " ['place', 1.0396881],\n",
       " ['\"', 0.50606525],\n",
       " [',', 0.3577559],\n",
       " ['to', 0.40588868],\n",
       " ['dalton', 4.4310036],\n",
       " ['##s', 1.3849921],\n",
       " [',', 0.20660445],\n",
       " ['to', 0.43497092],\n",
       " ['various', 0.4003929],\n",
       " ['other', 0.384777],\n",
       " ['places', 0.5136416],\n",
       " ['.', 12.598614],\n",
       " ['when', 0.40579298],\n",
       " ['he', 0.76323974],\n",
       " ['asked', 0.59239006],\n",
       " ['for', 0.7135903],\n",
       " ['this', 0.96757585],\n",
       " ['book', 1.1572016],\n",
       " [',', 10.6053915],\n",
       " ['the', 0.41701287],\n",
       " ['well', 0.37610212],\n",
       " ['educated', 0.7190064],\n",
       " ['american', 1.0636508],\n",
       " ['book', 2.588616],\n",
       " ['store', 3.5853028],\n",
       " ['assistants', 1.0366127],\n",
       " ['in', 0.7236024],\n",
       " ['most', 0.56256044],\n",
       " ['placed', 0.8150363],\n",
       " ['asked', 0.2688906],\n",
       " ['him', 1.4145352],\n",
       " ['to', 0.2850778],\n",
       " ['check', 0.5021478],\n",
       " ['out', 0.45321828],\n",
       " ['the', 0.61408573],\n",
       " ['thriller', 5.802701],\n",
       " ['section', 1.9565275],\n",
       " [',', 5.4214163],\n",
       " ['or', 0.8517173],\n",
       " ['then', 0.5242977],\n",
       " ['they', 0.582125],\n",
       " ['said', 0.2731427],\n",
       " ['that', 0.21142033],\n",
       " ['his', 1.2562897],\n",
       " ['book', 0.82968736],\n",
       " ['has', 0.27290452],\n",
       " ['not', 0.3301401],\n",
       " ['been', 0.21218494],\n",
       " ['published', 0.7494632],\n",
       " ['yet', 0.22998852],\n",
       " [',', 6.0519047],\n",
       " ['but', 0.3320167],\n",
       " ['they', 0.38656354],\n",
       " ['should', 0.26745835],\n",
       " ['receive', 0.7260612],\n",
       " ['the', 0.5352862],\n",
       " ['book', 0.83472997],\n",
       " ['soon', 0.3169874],\n",
       " ['.', 12.161003],\n",
       " ['in', 0.22033633],\n",
       " ['some', 0.26141676],\n",
       " ['places', 0.27312213],\n",
       " ['the', 0.36456043],\n",
       " ['assistants', 1.1560316],\n",
       " ['blunt', 0.34395388],\n",
       " ['##ly', 0.22754501],\n",
       " ['said', 0.23923507],\n",
       " ['that', 0.18231006],\n",
       " ['they', 0.36111778],\n",
       " ['don', 0.34467298],\n",
       " [\"'\", 0.35392442],\n",
       " ['t', 0.24566771],\n",
       " ['know', 0.15710798],\n",
       " ['of', 0.24339457],\n",
       " ['such', 0.2072375],\n",
       " ['an', 0.3061598],\n",
       " ['author', 0.9466822],\n",
       " [',', 1.2628119],\n",
       " ['or', 0.6961551],\n",
       " ['that', 0.20472437],\n",
       " ['he', 0.7173766],\n",
       " ['is', 0.2703864],\n",
       " ['not', 0.45169464],\n",
       " ['a', 0.45242512],\n",
       " ['well', 0.45112768],\n",
       " ['known', 0.5995258],\n",
       " ['living', 1.2135745],\n",
       " ['author', 0.98049265],\n",
       " [',', 0.14575009],\n",
       " ['so', 0.42971587],\n",
       " ['they', 0.3818894],\n",
       " ['don', 0.5307567],\n",
       " [\"'\", 0.6759192],\n",
       " ['t', 0.53316724],\n",
       " ['keep', 0.53271234],\n",
       " ['copies', 1.2276299],\n",
       " ['of', 0.41235524],\n",
       " ['his', 0.8259515],\n",
       " ['books', 1.2004],\n",
       " ['.', 11.609167],\n",
       " ['such', 0.28954482],\n",
       " ['is', 0.32935974],\n",
       " ['the', 0.18361981],\n",
       " ['life', 0.5591038],\n",
       " ['and', 0.36454648],\n",
       " ['times', 0.4945292],\n",
       " ['of', 0.3001637],\n",
       " ['america', 1.0421613],\n",
       " [',', 0.32237083],\n",
       " ['200', 0.50896156],\n",
       " ['+', 0.95722044],\n",
       " ['years', 0.3088412],\n",
       " ['after', 0.46907365],\n",
       " ['the', 0.57414657],\n",
       " ['revolution', 1.778044],\n",
       " ['.', 11.964096],\n",
       " ['cheers', 1.6690922],\n",
       " [',', 0.22150782],\n",
       " ['kent', 1.9959986]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_att[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"20ng\"\n",
    "tokens, att_weights = get_attention(dataset, 0, pd_datasets[dataset].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_att = set_word_attention(tokens[0], att_weights[0])\n",
    "doc_att"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
