{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2ff685",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Stacking of probabilities + TFIDF representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77ed12",
   "metadata": {},
   "source": [
    "# Libraries/Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa88d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:15.374316Z",
     "start_time": "2022-01-05T21:35:15.364727Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611c0acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:16.931458Z",
     "start_time": "2022-01-05T21:35:15.375650Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pandas as pd\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from joblib import load, dump\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6d15e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:16.946744Z",
     "start_time": "2022-01-05T21:35:16.932461Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../scr\")\n",
    "from constants import DATASETS, REPRESENTATIONS, ALGORITHMS\n",
    "from models import get_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9f0a1",
   "metadata": {},
   "source": [
    "Execution configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7ecdea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:16.961251Z",
     "start_time": "2022-01-05T21:35:16.948077Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_projeto = \"/home/christian/Documentos/mestrado/projetos/projeto_stacking2/stacking_text_classification\"\n",
    "\n",
    "dir_cls_input = f\"{dir_projeto}/data/classification_input\"\n",
    "dir_meta_input = f\"{dir_projeto}/data/meta_layer_input\"\n",
    "\n",
    "dir_output = f\"{dir_projeto}/data/stacking_output\"\n",
    "\n",
    "algorithms_execution = list(ALGORITHMS.values())  # All 18 algorithms\n",
    "datasets_execution = [\"webkb\", \"20ng\", \"acm\", \"reut\"]\n",
    "representation = \"tmk\"\n",
    "meta_layer = \"linear_svm\"\n",
    "n_folds = 10\n",
    "seed = 42\n",
    "\n",
    "# Otimization\n",
    "opt_cv = 5\n",
    "opt_n_iter = 10\n",
    "opt_scoring = \"f1_macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35114a",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456478ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:16.978524Z",
     "start_time": "2022-01-05T21:35:16.962696Z"
    },
    "code_folding": [
     0,
     3,
     15,
     21
    ]
   },
   "outputs": [],
   "source": [
    "def load_x_y(\n",
    "    file, \n",
    "    test_train : str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    loaded = np.load(file, allow_pickle=True)\n",
    "    \n",
    "    X = loaded[f\"X_{test_train}\"]\n",
    "    y = loaded[f\"y_{test_train}\"]\n",
    "    \n",
    "    if X.size == 1:\n",
    "        X = X.item()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def read_train_test_meta(\n",
    "    dir_meta_input: str,\n",
    "    dataset: str,\n",
    "    n_folds: int,\n",
    "    fold_id: int,\n",
    "    algorithms: List[str]\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Xs_train, Xs_test = [], []\n",
    "\n",
    "    for alg in algorithms:\n",
    "        file_train_meta = f\"{dir_meta_input}/{dataset}/{n_folds}_folds/{alg}/{fold_id}/train.npz\"\n",
    "        file_test_meta = f\"{dir_meta_input}/{dataset}/{n_folds}_folds/{alg}/{fold_id}/test.npz\"\n",
    "\n",
    "        X_train_meta, _ = load_x_y(file_train_meta, 'train')\n",
    "        X_test_meta, _ = load_x_y(file_test_meta, 'test')\n",
    "\n",
    "        Xs_train.append(X_train_meta)\n",
    "        Xs_test.append(X_test_meta)\n",
    "\n",
    "    X_train_meta = np.hstack(Xs_train)\n",
    "    X_test_meta = np.hstack(Xs_test)\n",
    "    \n",
    "    return X_train_meta, X_test_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dafe2c",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d3407a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:16.999055Z",
     "start_time": "2022-01-05T21:35:16.979727Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "def execute_optimization(\n",
    "    classifier_name: str, \n",
    "    file_model: str,\n",
    "    opt_cv: int, \n",
    "    opt_n_iter: int,\n",
    "    opt_scoring: str,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    seed: int = 42\n",
    "):\n",
    "    # Optimization/Training\n",
    "    classifier, hyperparameters = get_classifier(classifier_name=classifier_name)\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)), \n",
    "        (\"classifier\", classifier)\n",
    "    ])\n",
    "    hyperparameters = {f\"classifier__{k}\": v for k, v in hyperparameters.items()}\n",
    "    \n",
    "    optuna_search = OptunaSearchCV(\n",
    "        pipeline,\n",
    "        hyperparameters,\n",
    "        cv=StratifiedKFold(opt_cv, shuffle=True, random_state=seed),\n",
    "        error_score=\"raise\",\n",
    "        n_trials=opt_n_iter,\n",
    "        random_state=seed,\n",
    "        scoring=opt_scoring\n",
    "    )\n",
    "    \n",
    "    os.makedirs(os.path.dirname(file_model), exist_ok=True)\n",
    "    if os.path.exists(file_model):\n",
    "        print(\"\\tModel already executed! Loading model...\", end=\"\")\n",
    "        optuna_search = load(file_model)\n",
    "    else:\n",
    "        print(\"\\tExecuting model...\", end=\"\")\n",
    "        optuna_search.fit(X_train, y_train)\n",
    "        dump(optuna_search, file_model)\n",
    "        \n",
    "    return optuna_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c048de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:17.643048Z",
     "start_time": "2022-01-05T21:35:17.291150Z"
    },
    "code_folding": [
     29
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset WEBKB      - Fold 0    \n",
      "\tModel already executed! Loading model..."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 129 features, but StandardScaler is expecting 336 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5864/2930297499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_test_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mf1_macro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mf1_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stacking-text-classification/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stacking-text-classification/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stacking-text-classification/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stacking-text-classification/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stacking-text-classification/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 129 features, but StandardScaler is expecting 336 features as input."
     ]
    }
   ],
   "source": [
    "iterations = itertools.product(datasets_execution, range(n_folds))\n",
    "for (dataset, fold_id) in iterations:\n",
    "    print(f\"Dataset {dataset.upper():10s} - Fold {str(fold_id):5s}\")\n",
    "    \n",
    "    # Reading labels\n",
    "    file_train_cls = f\"{dir_cls_input}/{dataset}/{n_folds}_folds/{representation}/{fold_id}/train.npz\"\n",
    "    file_test_cls = f\"{dir_cls_input}/{dataset}/{n_folds}_folds/{representation}/{fold_id}/test.npz\"\n",
    "\n",
    "    _, y_train = load_x_y(file_train_cls, \"train\")\n",
    "    _, y_test = load_x_y(file_test_cls, \"test\")\n",
    "    \n",
    "    # Reading meta-layer input (classification probabilities)\n",
    "    X_train_meta, X_test_meta = read_train_test_meta(\n",
    "        dir_meta_input, dataset, n_folds, fold_id, algorithms_execution)\n",
    "    \n",
    "    # Reading extra features\n",
    "    X_train_extra = pd.read_pickle(\"../../data/extra_features/fold_0/webkb/train.csv\").values\n",
    "    X_test_extra = pd.read_pickle(\"../../data/extra_features/fold_0/webkb/test.csv\").values\n",
    "    \n",
    "    # Check shapes\n",
    "    assert len(y_test) == len(X_test_extra), \"X meta input differs from y shape.\"\n",
    "    assert len(y_train) == len(X_train_extra), \"X meta input differs from y shape.\"\n",
    "    \n",
    "    # Concat proba + Extra Fatures\n",
    "    new_X_train_meta = np.hstack([X_train_meta, X_train_extra])\n",
    "    new_X_test_meta = np.hstack([X_test_meta, X_test_extra])\n",
    "    \n",
    "    # Optimization/Training\n",
    "    file_model = f\"{dir_output}/{dataset}/{n_folds}_folds/{meta_layer}/proba_tmk_input/fold_{fold_id}/model.joblib\"\n",
    "    optuna_search = execute_optimization(\n",
    "        meta_layer, \n",
    "        file_model,\n",
    "        opt_cv, \n",
    "        opt_n_iter,\n",
    "        opt_scoring,\n",
    "        new_X_train_meta,\n",
    "        y_train\n",
    "    )\n",
    "    \n",
    "    # Prediction\n",
    "    y_pred = optuna_search.predict(new_X_test_meta)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    \n",
    "    msg = f\"\"\"\n",
    "    \\tF1-Macro: {f1_macro:.4f}\n",
    "    \\tF1-Micro: {f1_micro:.4f}\n",
    "    \"\"\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6351355f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-05T21:35:25.525405Z",
     "start_time": "2022-01-05T21:35:25.486484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "      <th>chi2</th>\n",
       "      <th>docs_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17126.324675</td>\n",
       "      <td>166.120697</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15072.780488</td>\n",
       "      <td>257.762628</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13426.634855</td>\n",
       "      <td>188.803384</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15890.393103</td>\n",
       "      <td>199.406828</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13987.573529</td>\n",
       "      <td>375.363024</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>13761.651961</td>\n",
       "      <td>271.388170</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>14769.755725</td>\n",
       "      <td>339.233880</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>13264.870229</td>\n",
       "      <td>411.894652</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>13976.547425</td>\n",
       "      <td>249.872397</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>14460.861244</td>\n",
       "      <td>374.455057</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7376 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               idf        chi2  docs_length\n",
       "0     17126.324675  166.120697           77\n",
       "1     15072.780488  257.762628          123\n",
       "2     13426.634855  188.803384          241\n",
       "3     15890.393103  199.406828          145\n",
       "4     13987.573529  375.363024           68\n",
       "...            ...         ...          ...\n",
       "7371  13761.651961  271.388170          204\n",
       "7372  14769.755725  339.233880          131\n",
       "7373  13264.870229  411.894652          131\n",
       "7374  13976.547425  249.872397          369\n",
       "7375  14460.861244  374.455057          209\n",
       "\n",
       "[7376 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"../../data/extra_features/fold_0/webkb/train.csv\").fillna(0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
