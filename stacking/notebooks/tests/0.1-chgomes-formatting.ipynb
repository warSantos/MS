{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T16:30:45.145434Z",
     "start_time": "2021-11-25T16:30:44.766260Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Datasets (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T16:30:45.149064Z",
     "start_time": "2021-11-25T16:30:45.147214Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir_datasets_raw = '../data/datasets/raw'\n",
    "# dir_datasets_preprocessed = '../data/datasets/preprocessed'\n",
    "# datasets = ['20ng', 'acm', 'agnews', 'imdb_reviews', 'reut', 'sogou', 'webkb', 'yahoo', 'yelp_2015']\n",
    "\n",
    "# dir_input_old = '/home/christian/arquivado/projeto_stacking/input'\n",
    "\n",
    "# for dset in datasets:\n",
    "#     print(f'Copying dataset {dset}')\n",
    "#     dir_raw_old = f'{dir_input_old}/{dset}/raw'\n",
    "#     dir_raw_new = f'{dir_datasets_raw}/{dset}'\n",
    "#     copy_tree(dir_raw_old, dir_raw_new)\n",
    "    \n",
    "#     dir_pre_old = f'{dir_input_old}/{dset}/preprocessed'\n",
    "#     dir_pre_new = f'{dir_datasets_preprocessed}/{dset}'\n",
    "#     copy_tree(dir_pre_old, dir_pre_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Classification Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-25T16:30:45.399937Z",
     "start_time": "2021-11-25T16:30:45.150746Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20ng fast_text_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "20ng fast_text_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "20ng pte_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "20ng pte_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "20ng tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "20ng tf_idf_1/fs 0 1 2 3 4 5 6 7 8 9 \n",
      "acm fast_text_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "acm fast_text_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "acm pte_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "acm pte_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "acm tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "acm tf_idf_1/fs 0 1 2 3 4 5 6 7 8 9 \n",
      "agnews fast_text_1/raw_folds 0 1 2 3 4 \n",
      "agnews pte_1/raw_folds 0 1 2 3 4 \n",
      "agnews tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 \n",
      "agnews tf_idf_1/fs 0 1 2 3 4 \n",
      "imdb_reviews fast_text_1/raw_folds 0 1 2 3 4 \n",
      "imdb_reviews pte_1/raw_folds 0 1 2 3 4 \n",
      "imdb_reviews tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 \n",
      "imdb_reviews tf_idf_1/fs 0 1 2 3 4 \n",
      "reut fast_text_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "reut fast_text_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "reut pte_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "reut pte_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "reut tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "reut tf_idf_1/fs 0 1 2 3 4 5 6 7 8 9 \n",
      "sogou fast_text_1/raw_folds 0 1 2 3 4 \n",
      "sogou pte_1/raw_folds 0 1 2 3 4 \n",
      "sogou tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 \n",
      "sogou tf_idf_1/fs 0 1 2 3 4 \n",
      "webkb fast_text_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "webkb fast_text_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "webkb pte_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "webkb pte_1/raw_folds 0 1 2 3 4 5 6 7 8 9 \n",
      "webkb tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 5 6 7 8 9 \n",
      "webkb tf_idf_1/fs 0 1 2 3 4 5 6 7 8 9 \n",
      "yahoo fast_text_1/raw_folds 0 1 2 3 4 \n",
      "yahoo pte_1/raw_folds 0 1 2 3 4 \n",
      "yahoo tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 \n",
      "yahoo tf_idf_1/fs 0 1 2 3 4 \n",
      "yelp_2015 fast_text_1/raw_folds 0 1 2 3 4 \n",
      "yelp_2015 pte_1/raw_folds 0 1 2 3 4 \n",
      "yelp_2015 tf_idf_1/meta_features_1/knn_cos 0 1 2 3 4 \n",
      "yelp_2015 tf_idf_1/fs 0 1 2 3 4 \n"
     ]
    }
   ],
   "source": [
    "datasets = ['20ng', 'acm', 'agnews', 'imdb_reviews', 'reut', 'sogou', 'webkb', 'yahoo', 'yelp_2015']\n",
    "repr_ids = {\n",
    "    \"fast_text_1/meta_features_1/knn_cos\": \"fmk\",\n",
    "    \"fast_text_1/raw_folds\": \"fr\",\n",
    "    \"pte_1/meta_features_1/knn_cos\": \"pmk\",\n",
    "    \"pte_1/raw_folds\": \"pr\",\n",
    "    \"tf_idf_1/meta_features_1/knn_cos\": \"tmk\",\n",
    "    \"tf_idf_1/fs\": \"tr\"\n",
    "}\n",
    "representations = repr_ids.keys()\n",
    "\n",
    "for dset, text_repr in product(datasets, representations):\n",
    "    text_repr_id = repr_ids[text_repr]\n",
    "    n_folds = 10 if dset in ['20ng', 'acm', 'reut', 'webkb'] else 5\n",
    "    \n",
    "    if (text_repr_id in ['fmk', 'pmk']) and (dset in ['agnews', 'imdb_reviews', 'sogou', 'yahoo', 'yelp_2015']):\n",
    "        continue\n",
    "    \n",
    "    print(dset, text_repr, end=' ')\n",
    "    for fold_id in range(n_folds):\n",
    "        print(fold_id, end=' ')\n",
    "        \n",
    "        # New X,y train/test\n",
    "        dir_cls_input = (\n",
    "            f'/home/christian/stacking_text_classification/data/classification_input/'\n",
    "            f'{dset}/{n_folds}_folds/{text_repr_id}/{fold_id}'\n",
    "        )\n",
    "        os.makedirs(dir_cls_input, exist_ok=True)\n",
    "        train_new = f'{dir_cls_input}/train'\n",
    "        test_new = f'{dir_cls_input}/test'\n",
    "        \n",
    "        if os.path.exists(f'{train_new}.npz') and os.path.exists(f'{test_new}.npz'):\n",
    "            continue\n",
    "            \n",
    "        # Read old X/y train/test\n",
    "        dir_input_old = (\n",
    "            f'/home/christian/arquivado/projeto_stacking/input/{dset}/representations'\n",
    "            f'/{n_folds}_folds/{text_repr}/fold_{fold_id}')\n",
    "        test_old = f'{dir_input_old}/test.gz'\n",
    "        train_old = f'{dir_input_old}/train.gz'\n",
    "        \n",
    "        X_train, y_train = load_svmlight_file(f=train_old, dtype=np.float64, zero_based=False)\n",
    "        X_test, y_test = load_svmlight_file(f=test_old, dtype=np.float64, zero_based=False)\n",
    "\n",
    "        if X_train.shape[1] > X_test.shape[1]:\n",
    "            X_test, y_test = load_svmlight_file(f=test_old, dtype=np.float64, zero_based=False, \n",
    "                                                n_features=X_train.shape[1])\n",
    "        elif X_train.shape[1] < X_test.shape[1]:\n",
    "            X_train, y_train = load_svmlight_file(f=train_old, dtype=np.float64, zero_based=False, \n",
    "                                                  n_features=X_test.shape[1])\n",
    "    \n",
    "        # Save new X/y train/test\n",
    "        np.savez_compressed(train_new, X_train=X_train, y_train=y_train)\n",
    "        np.savez_compressed(test_new, X_test=X_test, y_test=y_test)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting splits (save split files and representation configs files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
