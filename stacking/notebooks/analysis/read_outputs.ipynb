{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import stdev\n",
    "from scipy.stats import t as table_t\n",
    "from scipy.stats import f as table_f\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/home/welton/stacking_text_classification/data/stacking_output\"\n",
    "DATASETS = [\"webkb\", \"acm\", \"20ng\"]\n",
    "META_LAYERS = [\"svm_rbf\"]\n",
    "INPUT_TYPES = [\n",
    "\"num_feats/126/with_proba/True/combination/fwls/centroids\",\n",
    "\"num_feats/198/with_proba/True/combination/fwls/centroids\",\n",
    "\"num_feats/360/with_proba/True/combination/fwls/centroids\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES):\n",
    "    \n",
    "    dsets_scores = {}\n",
    "    results = []\n",
    "    iterations = itertools.product(DATASETS, META_LAYERS, INPUT_TYPES)\n",
    "\n",
    "    for (dset, meta_layer, inp_type) in iterations:\n",
    "        macro_list = []\n",
    "        micro_list = []\n",
    "        \n",
    "        if dset not in dsets_scores:\n",
    "            dsets_scores[dset] = {}\n",
    "        \n",
    "        if inp_type not in dsets_scores[dset]:\n",
    "            dsets_scores[dset][inp_type] = {}\n",
    "        \n",
    "        for fold in range(10):\n",
    "            json_score = f\"{BASE_DIR}/{dset}/10_folds/{meta_layer}/{inp_type}/fold_{fold}/scoring.json\"\n",
    "            if not os.path.exists(json_score):\n",
    "                json_score = f\"{BASE_DIR}/{dset}/10_folds/{meta_layer}/{inp_type}/fold_{fold}/scoring.json\"\n",
    "            if not os.path.exists(json_score):\n",
    "                continue\n",
    "            with open(json_score, 'r') as fd:\n",
    "                scoring = json.load(fd)\n",
    "            \n",
    "            dsets_scores[dset][inp_type][fold] = np.around(scoring['f1_macro'] * 100, decimals=2)\n",
    "            \n",
    "            macro_list.append(scoring['f1_macro'])\n",
    "            micro_list.append(scoring['f1_micro'])\n",
    "        mean_macro = np.around(np.mean(macro_list) * 100, decimals=2)\n",
    "        std_macro = np.around(np.std(macro_list) * 100, decimals=2)\n",
    "        mean_micro = np.around(np.mean(micro_list) * 100, decimals=2)\n",
    "        std_micro = np.around(np.std(micro_list) * 100, decimals=2)\n",
    "        results.append([dset, meta_layer, inp_type, mean_macro, std_macro, mean_micro, std_micro])\n",
    "    df = pd.DataFrame(results, columns=[\"Dataset\", \"MetaLayer\", \"InputType\", \"Macro\", \"Std Macro\", \"Micro\", \"Std Micro\"])\n",
    "    return df, dsets_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/stacking_text_classification/.env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/welton/stacking_text_classification/.env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/welton/stacking_text_classification/.env/lib/python3.8/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/welton/stacking_text_classification/.env/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/welton/stacking_text_classification/.env/lib/python3.8/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_79cb6_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Macro</th>\n",
       "      <th class=\"col_heading level0 col1\" >Std Macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >Micro</th>\n",
       "      <th class=\"col_heading level0 col3\" >Std Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_79cb6_row0_col0\" class=\"data row0 col0\" >82.96</td>\n",
       "      <td id=\"T_79cb6_row0_col1\" class=\"data row0 col1\" >2.08</td>\n",
       "      <td id=\"T_79cb6_row0_col2\" class=\"data row0 col2\" >88.28</td>\n",
       "      <td id=\"T_79cb6_row0_col3\" class=\"data row0 col3\" >1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_79cb6_row1_col0\" class=\"data row1 col0\" >71.90</td>\n",
       "      <td id=\"T_79cb6_row1_col1\" class=\"data row1 col1\" >2.01</td>\n",
       "      <td id=\"T_79cb6_row1_col2\" class=\"data row1 col2\" >80.30</td>\n",
       "      <td id=\"T_79cb6_row1_col3\" class=\"data row1 col3\" >0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_79cb6_row2_col0\" class=\"data row2 col0\" >85.94</td>\n",
       "      <td id=\"T_79cb6_row2_col1\" class=\"data row2 col1\" >0.98</td>\n",
       "      <td id=\"T_79cb6_row2_col2\" class=\"data row2 col2\" >86.25</td>\n",
       "      <td id=\"T_79cb6_row2_col3\" class=\"data row2 col3\" >0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe4c42dbe50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.to_string(index=False))\n",
    "df, dsets_scores = get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES)\n",
    "df[['Macro', 'Std Macro', 'Micro', 'Std Micro']].dropna().style.format(\"{:.2f}\").hide_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>MetaLayer</th>\n",
       "      <th>InputType</th>\n",
       "      <th>Macro</th>\n",
       "      <th>Std Macro</th>\n",
       "      <th>Micro</th>\n",
       "      <th>Std Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webkb</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>num_feats/126/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>82.96</td>\n",
       "      <td>2.08</td>\n",
       "      <td>88.28</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acm</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>num_feats/198/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>71.90</td>\n",
       "      <td>2.01</td>\n",
       "      <td>80.30</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20ng</td>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>num_feats/360/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>85.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>86.25</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset MetaLayer                                                 InputType  \\\n",
       "0   webkb   svm_rbf  num_feats/126/with_proba/True/combination/fwls/centroids   \n",
       "4     acm   svm_rbf  num_feats/198/with_proba/True/combination/fwls/centroids   \n",
       "8    20ng   svm_rbf  num_feats/360/with_proba/True/combination/fwls/centroids   \n",
       "\n",
       "   Macro  Std Macro  Micro  Std Micro  \n",
       "0  82.96       2.08  88.28       1.01  \n",
       "4  71.90       2.01  80.30       0.52  \n",
       "8  85.94       0.98  86.25       0.94  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().head(100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_31fe3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >proba</th>\n",
       "      <th class=\"col_heading level0 col1\" >num_feats/25/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col2\" >num_feats/50/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col3\" >num_feats/100/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col4\" >num_feats/200/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col5\" >num_feats/300/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col6\" >num_feats/400/with_proba/True/combination/concat/centroid_l2</th>\n",
       "      <th class=\"col_heading level0 col7\" >num_feats/500/with_proba/True/combination/concat/centroid_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row0_col0\" class=\"data row0 col0\" >85.08</td>\n",
       "      <td id=\"T_31fe3_row0_col1\" class=\"data row0 col1\" >84.63</td>\n",
       "      <td id=\"T_31fe3_row0_col2\" class=\"data row0 col2\" >85.53</td>\n",
       "      <td id=\"T_31fe3_row0_col3\" class=\"data row0 col3\" >85.13</td>\n",
       "      <td id=\"T_31fe3_row0_col4\" class=\"data row0 col4\" >85.37</td>\n",
       "      <td id=\"T_31fe3_row0_col5\" class=\"data row0 col5\" >85.28</td>\n",
       "      <td id=\"T_31fe3_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row1_col0\" class=\"data row1 col0\" >84.17</td>\n",
       "      <td id=\"T_31fe3_row1_col1\" class=\"data row1 col1\" >80.77</td>\n",
       "      <td id=\"T_31fe3_row1_col2\" class=\"data row1 col2\" >80.96</td>\n",
       "      <td id=\"T_31fe3_row1_col3\" class=\"data row1 col3\" >82.66</td>\n",
       "      <td id=\"T_31fe3_row1_col4\" class=\"data row1 col4\" >82.95</td>\n",
       "      <td id=\"T_31fe3_row1_col5\" class=\"data row1 col5\" >83.46</td>\n",
       "      <td id=\"T_31fe3_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row2_col0\" class=\"data row2 col0\" >81.43</td>\n",
       "      <td id=\"T_31fe3_row2_col1\" class=\"data row2 col1\" >83.26</td>\n",
       "      <td id=\"T_31fe3_row2_col2\" class=\"data row2 col2\" >82.45</td>\n",
       "      <td id=\"T_31fe3_row2_col3\" class=\"data row2 col3\" >83.70</td>\n",
       "      <td id=\"T_31fe3_row2_col4\" class=\"data row2 col4\" >82.83</td>\n",
       "      <td id=\"T_31fe3_row2_col5\" class=\"data row2 col5\" >82.83</td>\n",
       "      <td id=\"T_31fe3_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row3_col0\" class=\"data row3 col0\" >77.81</td>\n",
       "      <td id=\"T_31fe3_row3_col1\" class=\"data row3 col1\" >82.30</td>\n",
       "      <td id=\"T_31fe3_row3_col2\" class=\"data row3 col2\" >81.01</td>\n",
       "      <td id=\"T_31fe3_row3_col3\" class=\"data row3 col3\" >81.15</td>\n",
       "      <td id=\"T_31fe3_row3_col4\" class=\"data row3 col4\" >81.99</td>\n",
       "      <td id=\"T_31fe3_row3_col5\" class=\"data row3 col5\" >81.89</td>\n",
       "      <td id=\"T_31fe3_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row4_col0\" class=\"data row4 col0\" >79.57</td>\n",
       "      <td id=\"T_31fe3_row4_col1\" class=\"data row4 col1\" >79.04</td>\n",
       "      <td id=\"T_31fe3_row4_col2\" class=\"data row4 col2\" >79.72</td>\n",
       "      <td id=\"T_31fe3_row4_col3\" class=\"data row4 col3\" >80.10</td>\n",
       "      <td id=\"T_31fe3_row4_col4\" class=\"data row4 col4\" >80.37</td>\n",
       "      <td id=\"T_31fe3_row4_col5\" class=\"data row4 col5\" >80.37</td>\n",
       "      <td id=\"T_31fe3_row4_col6\" class=\"data row4 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row5_col0\" class=\"data row5 col0\" >84.88</td>\n",
       "      <td id=\"T_31fe3_row5_col1\" class=\"data row5 col1\" >81.72</td>\n",
       "      <td id=\"T_31fe3_row5_col2\" class=\"data row5 col2\" >82.01</td>\n",
       "      <td id=\"T_31fe3_row5_col3\" class=\"data row5 col3\" >81.62</td>\n",
       "      <td id=\"T_31fe3_row5_col4\" class=\"data row5 col4\" >82.21</td>\n",
       "      <td id=\"T_31fe3_row5_col5\" class=\"data row5 col5\" >82.70</td>\n",
       "      <td id=\"T_31fe3_row5_col6\" class=\"data row5 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row5_col7\" class=\"data row5 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row6_col0\" class=\"data row6 col0\" >84.83</td>\n",
       "      <td id=\"T_31fe3_row6_col1\" class=\"data row6 col1\" >84.72</td>\n",
       "      <td id=\"T_31fe3_row6_col2\" class=\"data row6 col2\" >85.63</td>\n",
       "      <td id=\"T_31fe3_row6_col3\" class=\"data row6 col3\" >86.01</td>\n",
       "      <td id=\"T_31fe3_row6_col4\" class=\"data row6 col4\" >86.11</td>\n",
       "      <td id=\"T_31fe3_row6_col5\" class=\"data row6 col5\" >86.21</td>\n",
       "      <td id=\"T_31fe3_row6_col6\" class=\"data row6 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row7_col0\" class=\"data row7 col0\" >84.63</td>\n",
       "      <td id=\"T_31fe3_row7_col1\" class=\"data row7 col1\" >86.45</td>\n",
       "      <td id=\"T_31fe3_row7_col2\" class=\"data row7 col2\" >86.02</td>\n",
       "      <td id=\"T_31fe3_row7_col3\" class=\"data row7 col3\" >87.68</td>\n",
       "      <td id=\"T_31fe3_row7_col4\" class=\"data row7 col4\" >86.41</td>\n",
       "      <td id=\"T_31fe3_row7_col5\" class=\"data row7 col5\" >86.23</td>\n",
       "      <td id=\"T_31fe3_row7_col6\" class=\"data row7 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row7_col7\" class=\"data row7 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row8_col0\" class=\"data row8 col0\" >87.68</td>\n",
       "      <td id=\"T_31fe3_row8_col1\" class=\"data row8 col1\" >84.83</td>\n",
       "      <td id=\"T_31fe3_row8_col2\" class=\"data row8 col2\" >84.84</td>\n",
       "      <td id=\"T_31fe3_row8_col3\" class=\"data row8 col3\" >84.73</td>\n",
       "      <td id=\"T_31fe3_row8_col4\" class=\"data row8 col4\" >84.92</td>\n",
       "      <td id=\"T_31fe3_row8_col5\" class=\"data row8 col5\" >85.72</td>\n",
       "      <td id=\"T_31fe3_row8_col6\" class=\"data row8 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row8_col7\" class=\"data row8 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31fe3_row9_col0\" class=\"data row9 col0\" >86.41</td>\n",
       "      <td id=\"T_31fe3_row9_col1\" class=\"data row9 col1\" >84.03</td>\n",
       "      <td id=\"T_31fe3_row9_col2\" class=\"data row9 col2\" >84.15</td>\n",
       "      <td id=\"T_31fe3_row9_col3\" class=\"data row9 col3\" >85.45</td>\n",
       "      <td id=\"T_31fe3_row9_col4\" class=\"data row9 col4\" >84.14</td>\n",
       "      <td id=\"T_31fe3_row9_col5\" class=\"data row9 col5\" >84.14</td>\n",
       "      <td id=\"T_31fe3_row9_col6\" class=\"data row9 col6\" >nan</td>\n",
       "      <td id=\"T_31fe3_row9_col7\" class=\"data row9 col7\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f37f4095880>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"webkb\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_test(\n",
    "    meta_layer=\"logistic_regression\",\n",
    "    system1=\"encoder/rep/fast_text/hidden_layers/3\",\n",
    "    system2=\"dist\",\n",
    "    dset=\"webkb\",\n",
    "    metric=\"f1_macro\",\n",
    "    alpha=0.01,\n",
    "    df=9\n",
    "):\n",
    "\n",
    "    t_value = table_t.ppf(1 - alpha/2, df)\n",
    "\n",
    "    residual = []\n",
    "    for fold in np.arange(10):\n",
    "\n",
    "        json_score = f\"{BASE_DIR}/{dset}/10_folds/{meta_layer}/{system2}/fold_{fold}/scoring.json\"\n",
    "        if not os.path.exists(json_score):\n",
    "            return None\n",
    "            \n",
    "        with open(json_score, 'r') as fd:\n",
    "            score_s2 = json.load(fd)[metric]\n",
    "\n",
    "        json_score = f\"{BASE_DIR}/{dset}/10_folds/logistic_regression/{system1}/fold_{fold}/scoring.json\"\n",
    "        with open(json_score, 'r') as fd:\n",
    "            score_s1 = json.load(fd)[metric]\n",
    "\n",
    "\n",
    "        residual.append(score_s1 - score_s2)\n",
    "\n",
    "    std = stdev(residual)\n",
    "    coef = t_value * (std / np.sqrt(df+1))\n",
    "    m = np.mean(residual)\n",
    "\n",
    "    return (np.around(m - coef, decimals=6), np.around(m + coef, decimals=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBKB\n",
      "\tproba | num_feats/126/with_proba/True/combination/fwls/centroids - (-0.020994, 0.034724)\n",
      "ACM\n",
      "\tproba | num_feats/198/with_proba/True/combination/fwls/centroids - (-0.00016, 0.034987)\n",
      "20NG\n",
      "\tproba | num_feats/360/with_proba/True/combination/fwls/centroids - (0.04462, 0.068416)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"webkb\", \"acm\", \"20ng\"]\n",
    "benchmark = [\"proba\"]\n",
    "proposals = [\n",
    "\"num_feats/126/with_proba/True/combination/fwls/centroids\",\n",
    "\"num_feats/198/with_proba/True/combination/fwls/centroids\",\n",
    "\"num_feats/360/with_proba/True/combination/fwls/centroids\", \n",
    "]\n",
    "\n",
    "iterations = itertools.product(datasets, benchmark, proposals)\n",
    "meta_layer = \"svm_rbf\"\n",
    "\n",
    "intervs = []\n",
    "for dset, bench, prop in iterations:\n",
    "    inter = paired_test(dset=dset, meta_layer=meta_layer, system1=bench, system2=prop)\n",
    "    if inter is not None:\n",
    "        print(f\"{dset}\".upper())\n",
    "        print(f\"\\t{bench} | {prop} - {inter}\")\n",
    "        intervs.append([dset, bench, f\"{meta_layer}/{prop}\", inter])\n",
    "\n",
    "t_interv = pd.DataFrame(intervs, columns=[\"Dataset\", \"Baseline\", \"Proposal\", \"Interval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Proposal</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webkb</td>\n",
       "      <td>proba</td>\n",
       "      <td>svm_rbf/num_feats/126/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>(-0.020994, 0.034724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acm</td>\n",
       "      <td>proba</td>\n",
       "      <td>svm_rbf/num_feats/198/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>(-0.00016, 0.034987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20ng</td>\n",
       "      <td>proba</td>\n",
       "      <td>svm_rbf/num_feats/360/with_proba/True/combination/fwls/centroids</td>\n",
       "      <td>(0.04462, 0.068416)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset Baseline  \\\n",
       "0   webkb    proba   \n",
       "1     acm    proba   \n",
       "2    20ng    proba   \n",
       "\n",
       "                                                           Proposal  \\\n",
       "0  svm_rbf/num_feats/126/with_proba/True/combination/fwls/centroids   \n",
       "1  svm_rbf/num_feats/198/with_proba/True/combination/fwls/centroids   \n",
       "2  svm_rbf/num_feats/360/with_proba/True/combination/fwls/centroids   \n",
       "\n",
       "                Interval  \n",
       "0  (-0.020994, 0.034724)  \n",
       "1   (-0.00016, 0.034987)  \n",
       "2    (0.04462, 0.068416)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_interv[t_interv.Proposal.str.contains(\"svm\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.020994, 0.034724)\n",
      "(-0.00016, 0.034987)\n",
      "(0.04462, 0.068416)\n"
     ]
    }
   ],
   "source": [
    "for i in t_interv[t_interv.Proposal.str.contains(\"svm\")].Interval.values:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Factor Factorial (2kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TYPES = [\n",
    "                \"with_proba/False/tfidf/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/1/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/1/simple/False\"]\n",
    "\n",
    "DATASETS = [\"big_acm\", \"short_acm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dsets_scores = get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"short_acm\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"big_acm\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic(qi, sqi, alpha, df):\n",
    "\n",
    "    ground = qi - table_t.ppf(1 - alpha/2, df) * sqi\n",
    "    ceiling = qi + table_t.ppf(1 - alpha/2, df) * sqi\n",
    "    #print(f\"{ground} ; {ceiling}\")\n",
    "    return [ground, ceiling]\n",
    "\n",
    "\n",
    "def two_kr(scores, alpha=0.05):\n",
    "    level_table = np.array([[1, -1, -1, 1], [1, 1, -1, -1], [1, -1, 1, -1], [1, 1, 1, 1]])\n",
    "    y_mean = np.mean(scores.values, axis=0)\n",
    "    model_params = (np.dot(level_table.T, y_mean) * 1/4)\n",
    "    values = scores.values\n",
    "    T_values = values.T\n",
    "    #np.zeros(values.shape[0], values.shape[1])\n",
    "    errors = []\n",
    "    for row in np.arange(level_table.shape[0]):\n",
    "        y_pred = 0\n",
    "        for col in np.arange(level_table.shape[1]):\n",
    "            y_pred += model_params[col] * level_table[row][col]\n",
    "        errors.append(T_values[row] - y_pred)\n",
    "    errors = np.array(errors)\n",
    "    SSE = np.sum(np.power(errors, 2))\n",
    "    SS0 = 4 * 10 * np.power(model_params[0],2)\n",
    "    SSY = np.sum(np.power(values, 2))\n",
    "    SST = SSY - SS0\n",
    "    SSA = 4 * 10 * np.power(model_params[1],2)\n",
    "    SSB = 4 * 10 * np.power(model_params[2],2)\n",
    "    SSAB = 4 * 10 * np.power(model_params[3],2)\n",
    "    df = 4 * (values.shape[0] - 1)\n",
    "    Se2 = SSE / (df)\n",
    "    Se = np.sqrt(Se2)\n",
    "    Sqi = Se / (np.sqrt(df))\n",
    "\n",
    "    ica = ic(model_params[1], Sqi, alpha, df)\n",
    "    icb = ic(model_params[2], Sqi, alpha, df)\n",
    "    icab = ic(model_params[3], Sqi, alpha, df)\n",
    "\n",
    "    output = f\"\"\"\n",
    "    Modelo - y = {model_params[0]} + {model_params[1]}*Xa + {model_params[2]}*Xb + {model_params[3]}*XaXb \n",
    "    Erro (SSE): {SSE}\n",
    "    Variação total (SST): {SST}\n",
    "    SSY: {SSY}\n",
    "    SS0: {SS0}\n",
    "    SSA: {SSA} - Explicação: {np.around((SSA / SST)*100, decimals=2)}%\n",
    "    SSB: {SSB} - Explicação: {np.around((SSB / SST)*100, decimals=2)}%\n",
    "    SSAB: {SSAB} - Explicação: {np.around((SSAB / SST)*100, decimals=2)}%\n",
    "    Não explicado (Erro experimental): {np.around((1 - SSA/SST - SSB/SST - SSAB/SST) * 100, decimals=2)}\n",
    "    Variância do erro (Se²/MSE): {Se2}\n",
    "    Desvio do erro (Se): {Se}\n",
    "    Desvio dos parâmetros (Sqi): {Sqi}\n",
    "    Confidence interval qa: {ica}\n",
    "    Confidence interval qb: {icb}\n",
    "    Confidence interval qab: {icab}\n",
    "    \"\"\"\n",
    "    print(output)\n",
    "\n",
    "    SSE = np.around(SSE, decimals=2)\n",
    "    SS0 = np.around(SS0, decimals=2)\n",
    "    SSY = np.around(SSY, decimals=2)\n",
    "    SST = np.around(SST, decimals=2)\n",
    "    SSA = np.around(SSA, decimals=2)\n",
    "    SSB = np.around(SSB, decimals=2)\n",
    "    SSAB = np.around(SSAB, decimals=2)\n",
    "    df = np.around(df, decimals=2)\n",
    "    Se2 = np.around(Se2, decimals=2)\n",
    "    Se = np.around(Se, decimals=2)\n",
    "    Sqi = np.around(Sqi, decimals=2)\n",
    "    ica = [np.around(ica[0], decimals=2), np.around(ica[1], decimals=2)]\n",
    "    icb = [np.around(icb[0], decimals=2), np.around(icb[1], decimals=2)]    \n",
    "    icab = [np.around(icab[0], decimals=2), np.around(icab[1], decimals=2)]\n",
    "    \n",
    "    report = [[\"SSE\", SSE],\n",
    "    [\"SS0\", SS0],\n",
    "    [\"SSY\", SSY],\n",
    "    [\"SST\", SST],\n",
    "    [\"SSA\", SSA],\n",
    "    [\"SSB\", SSB],\n",
    "    [\"SSAB\", SSAB],\n",
    "    [\"df\", df],\n",
    "    [\"Se2\", Se2],\n",
    "    [\"Se\", Se],\n",
    "    [\"Sqi\", Sqi],\n",
    "    [\"qa\", ica],\n",
    "    [\"qb\", icb],\n",
    "    [\"qab\", icab]]\n",
    "\n",
    "    #df = pd.DataFrame(report, columns=[\"metric\", \"value\"])\n",
    "    #df.value = np.around(df.value.astype(float).values, decimals=2)\n",
    "    return report#df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_kr(pd.DataFrame(dsets_scores[\"short_acm\"]), alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_kr(pd.DataFrame(dsets_scores[\"big_acm\"]), alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_factor(y_true):\n",
    "\n",
    "    NUM_REPS = y_true.shape[0]\n",
    "    NUM_LEVELS = y_true.shape[1]\n",
    "    general_mean = np.mean(y_true.values)\n",
    "    levels_mean = np.mean(y_true.values, axis=0) - general_mean\n",
    "    matrix_level_mean = np.repeat(levels_mean, NUM_REPS).reshape(NUM_REPS, -1).T\n",
    "    matrix_general_mean = np.repeat(general_mean, NUM_LEVELS *NUM_REPS).reshape(NUM_LEVELS, -1)\n",
    "    err = y_true.values.T - matrix_general_mean - matrix_level_mean\n",
    "    SSE = np.sum(np.power(err, 2))\n",
    "    SS0 = NUM_REPS * NUM_LEVELS * np.power(general_mean, 2)\n",
    "    SSA = NUM_REPS * np.sum(np.power(levels_mean, 2))\n",
    "    SSY = SS0 + SSA + SSE\n",
    "    SST = SSY - SS0\n",
    "    MSA = SSA / (NUM_LEVELS - 1)\n",
    "    MSE = SSE / (NUM_LEVELS * (NUM_REPS - 1))\n",
    "    Se2 = MSE\n",
    "    Saj = np.sqrt((Se2 * (NUM_LEVELS - 1)) / (NUM_LEVELS * NUM_REPS))\n",
    "    Fcalc = MSA / MSE\n",
    "    Ftab = table_f.ppf(0.90, NUM_LEVELS - 1, NUM_LEVELS * (NUM_REPS - 1))\n",
    "    \n",
    "    out_put = f\"\"\"\n",
    "    general_mean: {general_mean}\n",
    "    levels_mean: {levels_mean}\n",
    "    SSE: {SSE}\n",
    "    SS0: {SS0}\n",
    "    SSA: {SSA}\n",
    "    SSY: {SSY}\n",
    "    SST: {SST}\n",
    "    MSA: {MSA}\n",
    "    MSE/Se2: {MSE}\n",
    "    Se: {np.sqrt(Se2)}\n",
    "    Saj: {Saj}\n",
    "    Fcalc: {Fcalc}\n",
    "    Ftab: {Ftab}\n",
    "    \"\"\"\n",
    "    print(out_put)\n",
    "\n",
    "    for i in np.arange(levels_mean.shape[0]):\n",
    "        j = levels_mean[i]\n",
    "        print(ic(j, Saj, 0.1, NUM_LEVELS-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"big_acm\"]\n",
    "INPUT_TYPES = [\n",
    "                \"with_proba/False/chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/1/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/1/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/1/simple/False\"]\n",
    "                \n",
    "df, dsets_scores = get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"big_acm\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)\n",
    "folds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/chi2') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/tfidf/') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/tfidf-chi2') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"short_acm\"]\n",
    "INPUT_TYPES = [\n",
    "                \"with_proba/False/chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/1/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/1/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/tfidf-chi2/topn/1/simple/False\"]\n",
    "df, dsets_scores = get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"short_acm\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)\n",
    "folds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/chi2') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/tfidf/') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = folds_score[[ col for col in folds_score.columns if col.find('with_proba/False/tfidf-chi2') > -1 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_factor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"short_acm\"]\n",
    "INPUT_TYPES = [\n",
    "                \"with_proba/False/chi2/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/chi2/topn/1/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.3/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.5/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.7/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/0.9/simple/False\",\n",
    "                \"with_proba/False/tfidf/topn/1/simple/False\"]\n",
    "                \n",
    "df, dsets_scores = get_scores_dataset(DATASETS, META_LAYERS, INPUT_TYPES)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_score = pd.DataFrame(dsets_scores[\"short_acm\"])\n",
    "folds_score.style.format(\"{:.2f}\").hide_index()#.to_csv(\"temp.csv\", sep=\";\", index=False)\n",
    "folds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"/home/welton/stacking_text_classification/scr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def load_x_y(\n",
    "        file: str,\n",
    "        test_train: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    loaded = np.load(file, allow_pickle=True)\n",
    "\n",
    "    X = loaded[f\"X_{test_train}\"]\n",
    "    y = loaded[f\"y_{test_train}\"]\n",
    "\n",
    "    if X.size == 1:\n",
    "        X = X.item()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = load_svmlight_file(\"../../../meta-features/data/embeddings/bert/base/webkb/None/train0.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load[0]\n",
    "y = load[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimization import execute_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append(\"../../scr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scr.feature_selection.feature_importance import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PRE SELECTED FEATURES.\n"
     ]
    }
   ],
   "source": [
    "sort = fs.feature_importance(\"test\", X[500:], y[500:], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.load(\"../../data/feature_selection/test/feature_ranking.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X[500:], y[500:], n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rf.feature_importances_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.00040432403999e-06, 0.028993694885435177)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs[s[0]], fs[s[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028993694885435177"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(fs[s[0]], fs[s[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-x).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load(\"/home/welton/data/clfs_output/split_10_with_val/webkb/10_folds/svm/0/probas.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_test_bert(\n",
    "        data_source: str,\n",
    "        dataset: str,\n",
    "        algorithms: List[str],\n",
    "        n_folds: int,\n",
    "        fold_id: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    Xs_train, Xs_test = [], []\n",
    "\n",
    "    for clf in algorithms:\n",
    "        \n",
    "        probs_dir = f\"{data_source}/clfs_output/split_10_with_val/{dataset}/{n_folds}_folds/{clf}/{fold_id}\"\n",
    "\n",
    "        X_train_meta = np.load(f\"{probs_dir}/probas.npy\")\n",
    "        X_test_meta = np.load(f\"{probs_dir}/probas.npy\")\n",
    "\n",
    "        Xs_train.append(X_train_meta)\n",
    "        Xs_test.append(X_test_meta)\n",
    "\n",
    "    X_train_meta = np.hstack(Xs_train)\n",
    "    X_test_meta = np.hstack(Xs_test)\n",
    "\n",
    "    return X_train_meta, X_test_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = read_train_test_bert(\n",
    "    \"/home/welton/data\",\n",
    "    \"20ng\",\n",
    "    [\"svm\", \"gbm\"],\n",
    "    10,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
