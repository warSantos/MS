{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/project/.env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna.distributions import (IntDistribution,\n",
    "                                    FloatDistribution)\n",
    "from joblib import load, dump\n",
    "\n",
    "from local_utils import load_stacking_probs, build_clf_beans\n",
    "\n",
    "# Configs Optuna\n",
    "import warnings\n",
    "from optuna.exceptions import ExperimentalWarning\n",
    "from optuna.logging import set_verbosity, WARNING\n",
    "\n",
    "set_verbosity(WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\"]\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\", \"rep_bert\"]\n",
    "ORACLE_DIR = \"/home/welton/data/oracle\"\n",
    "ESTIMATOR_NAME = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement_mfs(probas, clf_target, fold, train_test):\n",
    "\n",
    "    main_preds = probas[clf_target][fold][train_test].argmax(axis=1)\n",
    "    preds = [ probas[clf][fold][train_test].argmax(axis=1) for clf in probas if clf != clf_target ]\n",
    "    preds = np.vstack(preds).T\n",
    "\n",
    "    div = []\n",
    "    #agree_classes = []\n",
    "    agree_sizes = []\n",
    "    for idx in np.arange(main_preds.shape[0]):\n",
    "        pred_class, agree_size = Counter(preds[idx]).most_common()[0]\n",
    "        if pred_class == main_preds[idx]:\n",
    "            div.append(0)\n",
    "        else:\n",
    "            div.append(1)\n",
    "        #agree_classes.append(pred_class)\n",
    "        agree_sizes.append(agree_size)\n",
    "\n",
    "    #return div, agree_classes, agree_sizes\n",
    "    return np.array(div), np.array(agree_sizes)\n",
    "\n",
    "def confidence_rate(probas, labels):\n",
    "\n",
    "    conf_hit = []\n",
    "    conf_freq, hits = build_clf_beans(probas, labels)\n",
    "    hits_rate = { np.trunc(bean*10)/10 : hits[bean] / conf_freq[bean] if bean in hits else 0 for bean in np.arange(0, 1, 0.1) }\n",
    "    preds = probas.argmax(axis=1)\n",
    "    for idx, predicted_class in enumerate(preds):\n",
    "        # Getting the probability of the predicted class\n",
    "        probability = probas[idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        conf_hit.append(hits_rate[bean])\n",
    "    return np.array(conf_hit)\n",
    "\n",
    "def hits_rate_by_class(probas, labels):\n",
    "\n",
    "    class_hits_rate = {}\n",
    "    preds = probas.argmax(axis=1)\n",
    "    # Vector with hits and misses.\n",
    "    hits = preds == labels\n",
    "    # For each label.\n",
    "    for label in np.unique(labels):\n",
    "        # Get the docs of the label.\n",
    "        class_docs = labels == label\n",
    "        class_hits_rate[label] = np.sum(hits[class_docs]) / np.sum(class_docs)\n",
    "    return np.array([ class_hits_rate[p] for p in preds ])\n",
    "\n",
    "def class_weights(probas, labels):\n",
    "\n",
    "    cw = { label:np.sum(labels == label) / labels.shape[0] for label in np.unique(labels) }\n",
    "    preds = probas.argmax(axis=1)\n",
    "    return np.array([ cw[p] for p in preds ])\n",
    "\n",
    "def get_clf(clf = \"xgboost\", n_jobs=5):\n",
    "\n",
    "    if clf == \"xgboost\":\n",
    "        CLF_XGB = XGBClassifier(random_state=42, verbosity=0, n_jobs=n_jobs)\n",
    "        HYP_XGB = {\n",
    "            \"n_estimators\": IntDistribution(low=100, high=1000, step=50),\n",
    "            \"learning_rate\": FloatDistribution(low=.01, high=.5),\n",
    "            \"eta\": FloatDistribution(low=.025, high=.5),\n",
    "            \"max_depth\": IntDistribution(low=1, high=14),\n",
    "            \"subsample\": FloatDistribution(low=.5, high=1.),\n",
    "            \"gamma\": FloatDistribution(low=1e-8, high=1.),\n",
    "            \"colsample_bytree\": FloatDistribution(low=.5, high=1.)\n",
    "        }\n",
    "        return CLF_XGB, HYP_XGB\n",
    "    else:\n",
    "        HYP_GBM = {}\n",
    "        return GradientBoostingClassifier(), HYP_GBM\n",
    "\n",
    "def execute_optimization(\n",
    "        classifier_name: str,\n",
    "        file_model: str,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        *,\n",
    "        opt_cv: int = 4,\n",
    "        opt_n_iter: int = 30,\n",
    "        opt_scoring: str = \"f1_macro\",\n",
    "        opt_n_jobs: int = 5,\n",
    "        clf_n_jobs: int = 5,\n",
    "        seed: int = 42,\n",
    "        load_model: bool = False\n",
    ") -> BaseEstimator:\n",
    "\n",
    "    classifier, hyperparameters = get_clf(classifier_name, n_jobs=clf_n_jobs)\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"classifier\", classifier)\n",
    "    ])\n",
    "    hyperparameters = {f\"classifier__{k}\": v for k, v in hyperparameters.items()}\n",
    "\n",
    "    optuna_search = OptunaSearchCV(\n",
    "        pipeline,\n",
    "        hyperparameters,\n",
    "        cv=StratifiedKFold(opt_cv, shuffle=True, random_state=seed),\n",
    "        error_score=\"raise\",\n",
    "        n_trials=opt_n_iter,\n",
    "        random_state=seed,\n",
    "        scoring=opt_scoring,\n",
    "        n_jobs=opt_n_jobs\n",
    "    )\n",
    "\n",
    "    if load_model and os.path.exists(file_model):\n",
    "        print(\"\\tModel already executed! Loading model...\", end=\"\")\n",
    "        optuna_search = load(file_model)\n",
    "    else:\n",
    "        print(\"\\tExecuting model...\", end=\"\")\n",
    "        optuna_search.fit(X_train, y_train)\n",
    "        dump(optuna_search, file_model)\n",
    "\n",
    "    return optuna_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DATASETS[0]\n",
    "probas = load_stacking_probs(dataset, CLFS, \"train_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_X_train = []\n",
    "global_X_test = []\n",
    "global_upper_train = []\n",
    "global_upper_test = []\n",
    "global_y_train = []\n",
    "global_y_test = []\n",
    "\n",
    "dist_train = csr_matrix(np.load(f\"/home/welton/data/meta_features/features/dist/{fold}/{dataset}/train.npz\")[\"X_train\"]).toarray()\n",
    "dist_test = csr_matrix(np.load(f\"/home/welton/data/meta_features/features/dist/{fold}/{dataset}/test.npz\")[\"X_test\"]).toarray()\n",
    "for target_clf in CLFS:\n",
    "    print(target_clf.upper())\n",
    "    probas_train = probas[target_clf][fold][\"train\"]\n",
    "    probas_test = probas[target_clf][fold][\"test\"]\n",
    "    cw_train = class_weights(probas_train, y_train)\n",
    "    cw_test = class_weights(probas_test, y_test)\n",
    "    hrc_train = hits_rate_by_class(probas_train, y_train)\n",
    "    hrc_test = hits_rate_by_class(probas_test, y_test)\n",
    "    conf_train = confidence_rate(probas_train, y_train)\n",
    "    conf_test = confidence_rate(probas_test, y_test)\n",
    "    div_train, ags_train = agreement_mfs(probas, target_clf, fold, \"train\")\n",
    "    div_test, ags_test = agreement_mfs(probas, target_clf, fold, \"test\")\n",
    "    scaled_ags_train = MinMaxScaler().fit_transform(ags_train.reshape(-1, 1)).reshape(-1)\n",
    "    scaled_ags_test = MinMaxScaler().fit_transform(ags_test.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    X_train = np.vstack([\n",
    "        cw_train,\n",
    "        hrc_train,\n",
    "        conf_train,\n",
    "        div_train,\n",
    "        ags_train,\n",
    "        scaled_ags_train\n",
    "    ]).T\n",
    "\n",
    "    X_train = np.hstack([probas_train, dist_train, X_train])\n",
    "    X_test = np.vstack([\n",
    "        cw_test,\n",
    "        hrc_test,\n",
    "        conf_test,\n",
    "        div_test,\n",
    "        ags_test,\n",
    "        scaled_ags_test\n",
    "    ]).T\n",
    "\n",
    "    X_test = np.hstack([probas_test, dist_test, X_test])\n",
    "\n",
    "    global_X_train.append(X_train)\n",
    "    global_X_test.append(X_test)\n",
    "\n",
    "    scores = []\n",
    "    preds_train = probas_train.argmax(axis=1)\n",
    "    upper_train = np.zeros(preds_train.shape[0])\n",
    "    upper_train[preds_train == y_train] = 1\n",
    "    global_upper_train.append(upper_train)\n",
    "\n",
    "    preds_test = probas_test.argmax(axis=1)\n",
    "    upper_test = np.zeros(preds_test.shape[0])\n",
    "    upper_test[preds_test == y_test] = 1\n",
    "    global_upper_test.append(upper_test)\n",
    "\n",
    "    global_y_train.append(y_train)\n",
    "    global_y_test.append(y_test)\n",
    "\n",
    "global_X_train = np.vstack(global_X_train)\n",
    "global_upper_train = np.hstack(global_upper_train)\n",
    "upper_test = np.hstack(global_upper_test)\n",
    "\n",
    "\n",
    "error_estimator, _ = get_clf(\"xgboost\", n_jobs=15)\n",
    "\n",
    "_ = error_estimator.fit(global_X_train, global_upper_train)\n",
    "y_pred = error_estimator.predict(np.vstack(global_X_test))\n",
    "\n",
    "scores.append([target_clf,\n",
    "precision_score(upper_test, y_pred, pos_label=0),\n",
    "recall_score(upper_test, y_pred, pos_label=0),\n",
    "f1_score(upper_test, y_pred, pos_label=0),\n",
    "accuracy_score(upper_test, y_pred)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_test, upper_test, alg in zip(global_X_test, global_upper_test, CLFS):\n",
    "    y_pred = clf.predict(np.vstack(X_test))\n",
    "    pc = precision_score(upper_test, y_pred, pos_label=0)\n",
    "    rc = recall_score(upper_test, y_pred, pos_label=0)\n",
    "    f1 = f1_score(upper_test, y_pred, pos_label=0)\n",
    "    acc = accuracy_score(upper_test, y_pred)\n",
    "    print(f\"{alg};{pc*100};{rc*100};{f1*100};{acc*100}\".replace('.',','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([7376]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.load(\"/home/welton/data/oracle/global_xgboost/clfs/webkb/0/train.npz\")['y'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([288, 535]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.load(\"/home/welton/data/oracle/global_xgboost/clfs/webkb/0/test.npz\")['y'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = FloatDistribution(low=1e-8, high=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"/home/welton/data/oracle/global_xgboost/error_estimator_bkp/webkb/0/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__n_estimators': 300,\n",
       " 'classifier__learning_rate': 0.11043661153099077,\n",
       " 'classifier__max_depth': 11,\n",
       " 'classifier__subsample': 0.8293121693743628,\n",
       " 'classifier__booster': 'gbtree',\n",
       " 'classifier__colsample_bytree': 0.650026359170959}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"f1_macro\": 78.19148936170212, \"precision\": 79.45945945945945, \"recall\": 76.96335078534031, \"accuracy\": 90.03645200486027}"
     ]
    }
   ],
   "source": [
    "!cat /home/welton/data/oracle/global_xgboost/clfs/webkb/kfr/0/scoring.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"f1_macro\": 44.57831325301205, \"precision\": 50.68493150684932, \"recall\": 39.784946236559136, \"accuracy\": 88.82138517618469}"
     ]
    }
   ],
   "source": [
    "!cat /home/welton/data/oracle/global_xgboost/clfs/webkb/rep_bert/0/scoring.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.18560410e-06, 6.79492950e-06, 7.80820847e-06, 8.82148743e-06,\n",
       "        9.59634781e-06, 1.16229057e-05, 1.23381615e-05, 1.30534172e-05,\n",
       "        1.31130219e-05, 1.31726265e-05, 1.33514404e-05, 1.45435333e-05,\n",
       "        1.47819519e-05, 1.55568123e-05, 1.59740448e-05, 1.64508820e-05,\n",
       "        1.72257423e-05, 2.08616257e-05, 2.18749046e-05, 2.19345093e-05,\n",
       "        2.29477882e-05, 2.33054161e-05, 2.34842300e-05, 2.44975090e-05,\n",
       "        2.47955322e-05, 2.51531601e-05, 2.54511833e-05, 3.10540199e-05,\n",
       "        3.14116478e-05, 3.29017639e-05, 3.29613686e-05, 3.60608101e-05,\n",
       "        3.65376472e-05, 3.68952751e-05, 3.92198563e-05, 4.00543213e-05,\n",
       "        4.11272049e-05, 4.19616699e-05, 4.21404839e-05, 4.58359718e-05,\n",
       "        4.89354134e-05, 5.07235527e-05, 5.69224358e-05, 6.06179237e-05,\n",
       "        6.07967377e-05, 6.31809235e-05, 6.52074814e-05, 6.59227371e-05,\n",
       "        6.63995743e-05, 6.72936440e-05, 6.86645508e-05, 7.06911087e-05,\n",
       "        7.09891319e-05, 7.30752945e-05, 7.56382942e-05, 7.77244568e-05,\n",
       "        7.83205032e-05, 7.85589218e-05, 8.14199448e-05, 8.18371773e-05,\n",
       "        8.71419907e-05, 9.07182693e-05, 9.10758972e-05, 9.67979431e-05,\n",
       "        1.05619431e-04, 1.14083290e-04, 1.25586987e-04, 1.36077404e-04,\n",
       "        1.39653683e-04, 1.55627728e-04, 1.56939030e-04, 1.69157982e-04,\n",
       "        1.73866749e-04, 1.77919865e-04, 1.88529491e-04, 2.11775303e-04,\n",
       "        2.18212605e-04, 2.27749348e-04, 2.51531601e-04, 2.84373760e-04,\n",
       "        2.86281109e-04, 3.17513943e-04, 3.55780125e-04, 3.62455845e-04,\n",
       "        3.72290611e-04, 3.85165215e-04, 3.91542912e-04, 4.47809696e-04,\n",
       "        4.55975533e-04, 6.58869743e-04, 6.82175159e-04, 7.72118568e-04,\n",
       "        7.80344009e-04, 7.97033310e-04, 8.03053379e-04, 8.36908817e-04,\n",
       "        8.40544701e-04, 8.60631466e-04, 8.99970531e-04, 9.72986221e-04,\n",
       "        1.19954348e-03, 1.26129389e-03, 1.38324499e-03, 1.39492750e-03,\n",
       "        1.41257048e-03, 1.41376257e-03, 1.53112411e-03, 1.60580873e-03,\n",
       "        1.62708759e-03, 1.89065933e-03, 2.02924013e-03, 2.13688612e-03,\n",
       "        2.15572119e-03, 2.38746405e-03, 2.54029036e-03, 2.55036354e-03,\n",
       "        2.93678045e-03, 3.08972597e-03, 3.71444225e-03, 3.91721725e-03,\n",
       "        3.99458408e-03, 4.01782990e-03, 4.45473194e-03, 4.79614735e-03,\n",
       "        5.02812862e-03, 6.02710247e-03, 6.25807047e-03, 7.07530975e-03,\n",
       "        7.20661879e-03, 7.22908974e-03, 8.79138708e-03, 1.06049776e-02,\n",
       "        1.06170177e-02, 1.13153458e-02, 1.19398236e-02, 1.29867196e-02,\n",
       "        1.38583183e-02, 1.43932700e-02, 1.46521926e-02, 1.57381296e-02,\n",
       "        1.74231529e-02, 1.80275440e-02, 2.07592845e-02, 2.14678645e-02,\n",
       "        2.30042338e-02, 2.34266520e-02, 2.56275535e-02, 2.57661939e-02,\n",
       "        2.68226862e-02, 3.10277343e-02, 3.15890312e-02, 3.43685746e-02,\n",
       "        4.13029790e-02, 5.31008840e-02, 6.12729192e-02, 6.48829341e-02,\n",
       "        6.55487776e-02, 7.19978809e-02, 7.47806430e-02, 8.01039934e-02,\n",
       "        8.12938213e-02, 9.27150249e-02, 1.03571951e-01, 1.04290545e-01,\n",
       "        1.19246721e-01, 1.39730632e-01, 1.43193603e-01, 1.71228766e-01,\n",
       "        1.82025313e-01, 1.97257996e-01, 2.43288875e-01, 2.45161474e-01,\n",
       "        2.50518620e-01, 2.61522770e-01, 2.64036775e-01, 2.64264762e-01,\n",
       "        2.78551817e-01, 2.85171986e-01, 3.04000378e-01, 3.19151640e-01,\n",
       "        3.43822241e-01, 4.05236840e-01, 4.10892785e-01, 1.00000000e+00]),\n",
       " array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1, 638]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.load(\"/home/welton/data/oracle/global_xgboost/clfs/webkb/kfr/0/test.npz\")['y'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22f5c821af8e0907655ca5fb88a86cc74c2a7ea210a5948302ed109ba043326b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
