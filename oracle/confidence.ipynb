{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"../analysis/utils/\")\n",
    "\n",
    "from utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\", \"20ng\", \"acm\", \"reut\"]\n",
    "\n",
    "CLFS = [\"rep_bert\"]\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\", \"rep_bert\"]\n",
    "\n",
    "THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_datasets = get_datasets(DATASETS, path=\"../../data/pd_datasets/__dset__.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, THRESHOLD):\n",
    "    \n",
    "    estimates = []\n",
    "    predictions = X.argmax(axis=1)\n",
    "    # For each prediction.\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        probability = X[idx][predicted_class]\n",
    "        if probability < THRESHOLD:\n",
    "            estimates.append(0)\n",
    "        else:\n",
    "            estimates.append(1)\n",
    "    return np.array(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBKB\n",
      "\tKPR\n",
      "\tKTR\n",
      "\tLPR\n",
      "\tLTR\n",
      "\tSFR\n",
      "\tSTMK\n",
      "\tXFR\n",
      "\tXPR\n",
      "\tXTR\n",
      "\tKFR\n",
      "\tKTMK\n",
      "\tLFR\n",
      "\tLTMK\n",
      "\tSPR\n",
      "\tSTR\n",
      "\tXLNET_SOFTMAX\n",
      "\tXTMK\n",
      "\tREP_BERT\n",
      "20NG\n",
      "\tKPR\n",
      "\tKTR\n",
      "\tLPR\n",
      "\tLTR\n",
      "\tSFR\n",
      "\tSTMK\n",
      "\tXFR\n",
      "\tXPR\n",
      "\tXTR\n",
      "\tKFR\n",
      "\tKTMK\n",
      "\tLFR\n",
      "\tLTMK\n",
      "\tSPR\n",
      "\tSTR\n",
      "\tXLNET_SOFTMAX\n",
      "\tXTMK\n",
      "\tREP_BERT\n",
      "ACM\n",
      "\tKPR\n",
      "\tKTR\n",
      "\tLPR\n",
      "\tLTR\n",
      "\tSFR\n",
      "\tSTMK\n",
      "\tXFR\n",
      "\tXPR\n",
      "\tXTR\n",
      "\tKFR\n",
      "\tKTMK\n",
      "\tLFR\n",
      "\tLTMK\n",
      "\tSPR\n",
      "\tSTR\n",
      "\tXLNET_SOFTMAX\n",
      "\tXTMK\n",
      "\tREP_BERT\n",
      "REUT\n",
      "\tKPR\n",
      "\tKTR\n",
      "\tLPR\n",
      "\tLTR\n",
      "\tSFR\n",
      "\tSTMK\n",
      "\tXFR\n",
      "\tXPR\n",
      "\tXTR\n",
      "\tKFR\n",
      "\tKTMK\n",
      "\tLFR\n",
      "\tLTMK\n",
      "\tSPR\n",
      "\tSTR\n",
      "\tXLNET_SOFTMAX\n",
      "\tXTMK\n",
      "\tREP_BERT\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for dset in DATASETS:\n",
    "    print(f\"{dset.upper()}\")\n",
    "    for clf in CLFS:\n",
    "        print(f\"\\t{clf.upper()}\")\n",
    "        for fold in np.arange(10):\n",
    "            probs_dir = f\"/home/welton/data/clfs_output/split_10/{dset}/10_folds/{clf}/{fold}\"\n",
    "            # Loading probabilities.\n",
    "            X_train = np.load(f\"{probs_dir}/train.npz\")[\"X_train\"]\n",
    "            labels_dir = f\"/home/welton/data/datasets/labels/split_10/{dset}/{fold}\"\n",
    "            train_labels = np.load(f\"{labels_dir}/train.npy\")\n",
    "            \n",
    "            X_test = np.load(f\"{probs_dir}/test.npz\")[\"X_test\"]\n",
    "            test_est = predict(X_test, THRESHOLD)\n",
    "            \n",
    "            # Saving probabilities to confidence.\n",
    "            output_dir = f\"/home/welton/data/oracle/confidence/{THRESHOLD}/{dset}/{clf}/{fold}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            y = np.load(f\"/home/welton/data/oracle/upper_bound/{dset}/{clf}/{fold}/train.npz\")[\"y\"]\n",
    "            normal = np.zeros(y.shape[0]) + 1\n",
    "            np.savez(f\"{output_dir}/test\", y=test_est)\n",
    "            np.savez(f\"{output_dir}/train\", y=normal)\n",
    "\n",
    "            ## Comparing this strategy with \n",
    "            #y_true = np.load(f\"/home/welton/data/oracle/upper_bound/{dset}/{clf}/{fold}/test.npz\")[\"y\"]\n",
    "            #prec = np.round(precision_score(y_true, test_est, zero_division=1, pos_label=0) * 100, decimals=2)\n",
    "            #rec = np.round(recall_score(y_true, test_est, pos_label=0) * 100, decimals=2)\n",
    "            #print(f\"\\t\\tFOLD: {fold} - Precision: {prec} Recall: {rec}\")\n",
    "            #scores.append([dset, clf, fold, prec, rec])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores, columns=[\"DATASET\", \"CLF\", \"Precision\", \"Recall\", \"Fold\"])\n",
    "df.to_excel(f\"data/{THRESHOLD}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.load(\"../../data/oracle/upper_bound/webkb/lfr/0/test.npz\").keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([   3, 1889])), (array([0, 1]), array([   34, 16920])))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.1/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.1/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([  63, 1829])), (array([0, 1]), array([  701, 16253])))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.2/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.2/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([ 196, 1696])), (array([0, 1]), array([ 1904, 15050])))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.3/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.3/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
