{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"../analysis/utils/\")\n",
    "\n",
    "from utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\", \"20ng\"]#, \"acm\", \"reut\"]\n",
    "\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\"]\n",
    "\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_datasets = get_datasets(DATASETS, path=\"../../data/pd_datasets/__dset__.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dfs = get_datasets(DATASETS, path=\"../../stacking/output/datasets/__dset__.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    print(np.unique(old_dfs[dataset].classes.values == pd_datasets[dataset].label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5932826976735716"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pd_datasets[\"webkb\"].label.values, pd_datasets[\"webkb\"].kpr.values, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_probas = {}\n",
    "probas_by_fold = {}\n",
    "for dset in DATASETS:\n",
    "    d_probas[dset] = {}\n",
    "    probas_by_fold[dset] = {}\n",
    "    for clf in CLFS:\n",
    "        probas_by_fold[dset][clf] = {}\n",
    "        lprobas = []\n",
    "        for fold in np.arange(10):\n",
    "            probs_path = f\"/home/welton/data/clfs_output/split_10/{dset}/10_folds/{clf}/{fold}/test.npz\"\n",
    "            probas_by_fold[dset][clf][fold] = np.load(probs_path)[\"X_test\"]\n",
    "            lprobas.append(probas_by_fold[dset][clf][fold])\n",
    "        d_probas[dset][clf] = np.vstack(lprobas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf_beans(clf_probas, df):\n",
    "    predictions = clf_probas.argmax(axis=1)\n",
    "    confidence_freq = {}\n",
    "    hits = {}\n",
    "    # For each prediction\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        \n",
    "        # Getting the probability of the predicted class\n",
    "        probability = clf_probas[idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        # Adding the bean in confidence if is not there yet.\n",
    "        if bean not in confidence_freq:\n",
    "            confidence_freq[bean] = 0\n",
    "        confidence_freq[bean] += 1\n",
    "        # Veryfing if the predicted class was right.\n",
    "        if predicted_class == df.label.values[idx]:\n",
    "            if bean not in hits:\n",
    "                hits[bean] = 0\n",
    "            hits[bean] += 1\n",
    "    return confidence_freq, hits\n",
    "\n",
    "def get_miss_predictor(confidence_freq, hits, threshold=0.3):\n",
    "\n",
    "    predictor = {}\n",
    "    for bean in hits:\n",
    "        hits_rate = hits[bean] / confidence_freq[bean]\n",
    "        if hits_rate < threshold:\n",
    "            predictor[bean] = True\n",
    "    return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = {}\n",
    "for dataset in DATASETS:\n",
    "    predictors[dataset] = {}\n",
    "    for clf in CLFS:\n",
    "        confidence_freq, hits = build_clf_beans(d_probas[dataset][clf], pd_datasets[dataset])\n",
    "        predictors[dataset][clf] = get_miss_predictor(confidence_freq, hits, THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatives = []\n",
    "\n",
    "# For each fold.\n",
    "for fold in np.arange(10):\n",
    "    predictions = probas_by_fold[\"webkb\"][\"kpr\"][fold].argmax(axis=1)\n",
    "    # For each prediction.\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        # Getting the prediction confidence.\n",
    "        probability = d_probas[\"webkb\"][\"kpr\"][idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        # Estimating classification error.\n",
    "        if bean in predictors[\"webkb\"][\"kpr\"]:\n",
    "            estimatives.append(0)\n",
    "        else:\n",
    "            estimatives.append(1)\n",
    "\n",
    "    np.load(f\"../../data/oracle/upper_bound/webkb/kpr/0/test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14285714, 0.57142857, 0.07142857, ..., 0.        , 0.21428571,\n",
       "        0.        ],\n",
       "       [0.57142857, 0.        , 0.        , ..., 0.        , 0.42857143,\n",
       "        0.        ],\n",
       "       [0.71428571, 0.14285714, 0.        , ..., 0.        , 0.14285714,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.07142857, 0.        , ..., 0.        , 0.        ,\n",
       "        0.92857143],\n",
       "       [0.21428571, 0.14285714, 0.14285714, ..., 0.07142857, 0.07142857,\n",
       "        0.35714286],\n",
       "       [0.07142857, 0.        , 0.        , ..., 0.        , 0.07142857,\n",
       "        0.78571429]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_by_fold[\"webkb\"][\"kpr\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
