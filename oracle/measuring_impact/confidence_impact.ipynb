{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/welton/data\"\n",
    "PROBS_DIR = f\"{DATA_DIR}/normal_probas/split_10\"\n",
    "LABELS_DIR = f\"{DATA_DIR}/datasets/labels/split_10\"\n",
    "UPPER_DIR = f\"{DATA_DIR}/oracle/upper_bound/normal_probas\"\n",
    "STACKING_DIR = f\"{DATA_DIR}/stacking/stacking_output\"\n",
    "CLFS = [\"bert\", \"xlnet\", \"ktmk\", \"ktr\", \"lstmk\", \"lstr\", \"ltr\"]\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert_normal_probas/ktmk_normal_probas/ktr_normal_probas/lstmk_normal_probas/lstr_normal_probas/ltr_normal_probas/xlnet_normal_probas'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs_stack = '/'.join(sorted([f\"{clf}_normal_probas\" for clf in CLFS ]))\n",
    "clfs_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probs(probs_source: str,\n",
    "               dataset: str,\n",
    "               clfs: list,\n",
    "               fold: int):\n",
    "\n",
    "    probas = {}\n",
    "    for clf in clfs:\n",
    "        probas[clf] = {}\n",
    "        probas_dir = f\"{probs_source}/{dataset}/10_folds/{clf}/{fold}/\"\n",
    "        train_load = np.load(f\"{probas_dir}/train.npz\")\n",
    "        test_load = np.load(f\"{probas_dir}/test.npz\")\n",
    "        probas[clf][\"X_train\"] = train_load[\"X_train\"]\n",
    "        probas[clf][\"X_test\"] = test_load[\"X_test\"]\n",
    "    return probas\n",
    "\n",
    "def load_y(labels_dir: int, dataset: str, fold: int):\n",
    "\n",
    "    ldir = f\"{labels_dir}/{dataset}/{fold}\"\n",
    "    return np.load(f\"{ldir}/train.npy\"), np.load(f\"{ldir}/test.npy\")\n",
    "\n",
    "def load_upper(data_source: str, dataset: str, clfs: str, fold: int):\n",
    "\n",
    "    upper = {}\n",
    "    for clf in clfs:\n",
    "        upper[clf] = {}\n",
    "        upper_dir = f\"{data_source}/{dataset}/10_folds/{clf}/{fold}/\"\n",
    "        upper[clf][\"y_train\"] = np.load(f\"{upper_dir}/train.npz\")['y']\n",
    "        upper[clf][\"y_test\"] = np.load(f\"{upper_dir}/test.npz\")['y']\n",
    "    return upper\n",
    "\n",
    "def fix_probas(clfs: list, y: np.ndarray, probas: dict, alfa: float):\n",
    "    \n",
    "    new_probas = []\n",
    "    for clf in clfs:\n",
    "        clf_probas = []\n",
    "        y_pred = probas[clf][\"X_test\"].argmax(axis=1)\n",
    "        for doc_idx, doc_proba in enumerate(probas[clf][\"X_test\"]):\n",
    "            class_proba = y_pred[doc_idx]\n",
    "            bucket = np.trunc(doc_proba[class_proba] * 10) / 10\n",
    "            bucket = doc_proba[class_proba]\n",
    "            if y_pred[doc_idx] != y[doc_idx] and bucket == alfa:\n",
    "                clf_probas.append(np.zeros(doc_proba.shape[0]))\n",
    "            else:\n",
    "                clf_probas.append(doc_proba)\n",
    "        new_probas.append(np.vstack(clf_probas))\n",
    "    return np.hstack(new_probas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_layer = \"10_folds/logistic_regression/normal_probas\"\n",
    "dataset = \"acm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = load_probs(PROBS_DIR, \"acm\", CLFS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers = load_upper(UPPER_DIR, \"acm\", CLFS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "max_fixes = 0\n",
    "for fold in np.arange(10):\n",
    "    \n",
    "    stats[fold] = {}\n",
    "\n",
    "    y_train, y_test = load_y(LABELS_DIR, dataset, fold)\n",
    "    probas = load_probs(PROBS_DIR, dataset, CLFS, fold)\n",
    "    model = load(f\"{STACKING_DIR}/{dataset}/{meta_layer}/{clfs_stack}/fold_{fold}/model.joblib\")\n",
    "    \n",
    "    for alfa in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "        \n",
    "        X_test = fix_probas(CLFS, y_test, probas,  alfa)\n",
    "        y_pred = model.predict(X_test)\n",
    "        stats[fold][alfa] = f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_alfas = { interval: 0 for interval in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] }\n",
    "for interval in mean_alfas:\n",
    "    for fold in np.arange(10):\n",
    "        mean_alfas[interval] += stats[fold][interval] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.7395255498713335,\n",
       " 0.1: 0.7395255498713335,\n",
       " 0.2: 0.7395561740122022,\n",
       " 0.3: 0.7396262544244857,\n",
       " 0.4: 0.7395890697907915,\n",
       " 0.5: 0.7395971831847278,\n",
       " 0.6: 0.7397870396389669,\n",
       " 0.7: 0.7396918945771279,\n",
       " 0.8: 0.7397553117099712,\n",
       " 0.9: 0.7399002885368456,\n",
       " 1: 0.7396813819926662}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_alfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "73,95\n",
    "73,95\n",
    "73,95\n",
    "73,96\n",
    "73,95\n",
    "73,95\n",
    "73,97\n",
    "73,96\n",
    "73,97\n",
    "73,99\n",
    "73,96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
