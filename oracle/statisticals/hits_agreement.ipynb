{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"../analysis/utils/\")\n",
    "\n",
    "from utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\"]\n",
    "\n",
    "CLFS = [\"rep_bert\"]\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\", \"rep_bert\"]\n",
    "\n",
    "THRESHOLD = [0.1, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_datasets = get_datasets(DATASETS, path=\"../../data/pd_datasets/__dset__.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    \"webkb\": {\n",
    "        \"kpr\" : { 0.2: True, 0.3: True, 0.4: True },\n",
    "        \"ktr\": {},\n",
    "        \"lpr\": { 0.2: True, 0.3: True, 0.4: True, 0.5: True, 0.6: True, 0.7: True},\n",
    "        \"ltr\": { 0.1: True, 0.2: True, 0.3: True, 0.4: True, 0.5: True },\n",
    "        \"sfr\": { 0.1: True, 0.2: True, 0.3: True },\n",
    "        \"stmk\": { 0.1: True },\n",
    "        \"xfr\": {},\n",
    "        \"xpr\": { 0.1: True, 0.2: True, 0.4: True, 0.6: True},\n",
    "        \"xtr\": { 0.1: True, 0.2: True, 0.3: True, 0.4: True, 0.5: True },\n",
    "        \"kfr\": { 0.1: True, 0.2: True, 0.3: True, 0.4: True, 0.5: True, 0.5: True, 0.6: True, 0.7: True, 0.8: True },\n",
    "        \"ktmk\": { 0.3: True, 0.5: True},\n",
    "        \"lfr\": { 0.1: True, 0.2: True, 0.3: True, 0.4: True, 0.5: True, 0.5: True, 0.6: True},\n",
    "        \"ltmk\": { 0.3: True, 0.4: True, 0.5: True },\n",
    "        \"spr\": { 0.1: True, 0.2: True, 0.3: True },\n",
    "        \"str\": { 0.1: True, 0.2: True },\n",
    "        \"xlnet_softmax\": { 0.1: True, 0.2: True, 0.3: True, 0.4: True, 0.5: True, 0.5: True },\n",
    "        \"xtmk\": { 0.2: True, 0.3: True, 0.5: True, 0.6: True,},\n",
    "        \"rep_bert\": { 0.1: True, 0.2: True, 0.3: True }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, estimator, df):\n",
    "    \n",
    "    conc_pred = df.conc_pred.values\n",
    "    conc_size = df.conc_size.values\n",
    "    estimates = []\n",
    "    predictions = X.argmax(axis=1)\n",
    "    # For each prediction.\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        probability = X[idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        # If this confidence has a miss rate greater than THRESHOLD (wether it is in the dictionary or not)\n",
    "        if bean in estimator or ( bean < 0.7 and predicted_class != conc_pred[idx] and conc_size[idx] > 1):\n",
    "            estimates.append(0)\n",
    "        else:\n",
    "            estimates.append(1)\n",
    "    return np.array(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spr', 'kpr', 'xtr', 'xfr', 'stmk', 'ltmk', 'lpr', 'str', 'ltr', 'lfr',\n",
       "       'kfr', 'xlnet', 'ktmk', 'rep_bert', 'ktr', 'bert', 'sfr', 'xtmk',\n",
       "       'xlnet_softmax', 'xpr', 'label', 'fold_id', 'docs', 'conc_size',\n",
       "       'hit_counts', 'conc_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_datasets[\"webkb\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = []\n",
    "for dset in DATASETS:\n",
    "    #print(f\"{dset.upper()}\")\n",
    "    for clf in CLFS:\n",
    "        #print(f\"\\t{clf.upper()}\")\n",
    "        for fold in np.arange(10):\n",
    "            probs_dir = f\"/home/welton/data/clfs_output/split_10/{dset}/10_folds/{clf}/{fold}\"\n",
    "            # Loading probabilities.\n",
    "            X_train = np.load(f\"{probs_dir}/train.npz\")[\"X_train\"]\n",
    "            labels_dir = f\"/home/welton/data/datasets/labels/split_10/{dset}/{fold}\"\n",
    "            train_labels = np.load(f\"{labels_dir}/train.npy\")\n",
    "            \n",
    "            X_test = np.load(f\"{probs_dir}/test.npz\")[\"X_test\"]\n",
    "            df = pd_datasets[dset]\n",
    "\n",
    "            # Applying estimator on train and test.\n",
    "            estimator = estimators[dset]\n",
    "            test_est = predict(X_test, estimator, df[df.fold_id == fold])\n",
    "            \n",
    "            # Saving probabilities to hits_agreement test.\n",
    "            output_dir = f\"/home/welton/data/oracle/hits_agreement/{dset}/{clf}/{fold}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            upper_y_train = np.load(f\"/home/welton/data/oracle/upper_bound/{dset}/{clf}/{fold}/train.npz\")[\"y\"]\n",
    "            normal = np.zeros(upper_y_train.shape[0]) + 1\n",
    "            np.savez(f\"{output_dir}/test\", y=test_est)\n",
    "            np.savez(f\"{output_dir}/train\", y=normal)\n",
    "\n",
    "            # Comparing this strategy with \n",
    "            upper_y_test = np.load(f\"/home/welton/data/oracle/upper_bound/{dset}/{clf}/{fold}/test.npz\")[\"y\"]\n",
    "            prec = np.round(precision_score(upper_y_test, test_est, zero_division=1, pos_label=0) * 100, decimals=2)\n",
    "            rec = np.round(recall_score(upper_y_test, test_est, pos_label=0) * 100, decimals=2)\n",
    "            macro = np.round(f1_score(upper_y_test, test_est, pos_label=0) * 100, decimals=2)\n",
    "            #print(f\"\\t\\tFOLD: {fold} - Precision: {prec} Recall: {rec}\")\n",
    "            scores.append([dset, clf, prec, rec, macro, fold])\n",
    "            df = pd.DataFrame(scores, columns=[\"DATASET\", \"CLF\", \"Precision\", \"Recall\", \"Macro\", \"Fold\"])\n",
    "            df.to_excel(f\"data/hits_agree.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.load(\"../../data/oracle/hits_agreement/webkb/lfr/0/test.npz\").keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([125, 698])), (array([1.]), array([7376])))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_agreement/webkb/kpr/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_agreement/webkb/kpr/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
