{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"../analysis/utils/\")\n",
    "\n",
    "from utils import get_datasets\n",
    "from local_utils import build_clf_beans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\", \"20ng\", \"acm\", \"reut\"]\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\", \"rep_bert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_path = \"/home/welton/data/pd_datasets/__dset__.csv\"\n",
    "pd_datasets = get_datasets(DATASETS, path=pd_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stacking_probs(dataset: str, CLFS: list, train_test: str = \"train\"):\n",
    "\n",
    "    probs = {}\n",
    "    for clf in CLFS:\n",
    "        probs[clf] = {}\n",
    "        for fold in np.arange(10):\n",
    "            probs[clf][fold] = {}\n",
    "            prob_dir = f\"/home/welton/data/clfs_output/split_10/{dataset}/10_folds/{clf}/{fold}/\"\n",
    "            if train_test == \"train\":\n",
    "                file_path = f\"{prob_dir}/train.npz\"\n",
    "                probs[clf][fold][\"train\"] = np.load(file_path)[f\"X_tain\"]\n",
    "            elif train_test == \"test\":\n",
    "                file_path = f\"{prob_dir}/test.npz\"\n",
    "                probs[clf][fold][\"test\"] = np.load(file_path)[f\"X_test\"]\n",
    "            else:\n",
    "                file_path = f\"{prob_dir}/train.npz\"\n",
    "                probs[clf][fold][\"train\"] = np.load(file_path)[f\"X_train\"]\n",
    "                file_path = f\"{prob_dir}/test.npz\"\n",
    "                probs[clf][fold][\"test\"] = np.load(file_path)[f\"X_test\"]\n",
    "    return probs\n",
    "\n",
    "def load_labels(dataset: str, fold: int):\n",
    "\n",
    "    file_path = f\"/home/welton/data/clfs_output/split_10/{dataset}/10_folds/lfr/{fold}/train.npz\"\n",
    "    y_train = np.load(file_path)[\"y_train\"]\n",
    "    file_path = f\"/home/welton/data/clfs_output/split_10/{dataset}/10_folds/lfr/{fold}/test.npz\"\n",
    "    y_test = np.load(file_path)[\"y_test\"]\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBKB\n",
      "\tMacro - 75.19\n",
      "20NG\n",
      "\tMacro - 91.78\n",
      "ACM\n",
      "\tMacro - 70.42\n",
      "REUT\n",
      "\tMacro - 36.52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in DATASETS:\n",
    "    print(dataset.upper())\n",
    "    scores = []\n",
    "    probs = load_stacking_probs(dataset, CLFS, \"train_test\")\n",
    "    # For each fold.\n",
    "    for fold in np.arange(10):\n",
    "        y_train, y_test = load_labels(dataset, fold)\n",
    "        C = len(np.unique(np.hstack([y_train, y_test])))\n",
    "        majority = np.zeros((y_test.shape[0], C))\n",
    "        # For each classifier.\n",
    "        for clf in CLFS:\n",
    "            # Get confidence hits rate.\n",
    "            conf_freq, hit_counts = build_clf_beans(probs[clf][fold][\"train\"], y_train)\n",
    "            hits_by_conf = { key: hit_counts[key] / conf_freq[key] if key in hit_counts else 0 for key in conf_freq }\n",
    "            # Apply majority vote weighted by confidence rate.\n",
    "            test_probas = probs[clf][fold][\"test\"]\n",
    "            predictions = test_probas.argmax(axis=1)\n",
    "            for idx, predicted_class in enumerate(predictions):\n",
    "                probability = test_probas[idx][predicted_class] * 10\n",
    "                bean = np.trunc(probability) / 10\n",
    "                bean = 0.9 if bean >= 1 else bean\n",
    "                if bean in hits_by_conf:\n",
    "                    majority[idx][predicted_class] += probability * hits_by_conf[bean]\n",
    "                    #majority[idx][predicted_class] += bean * hits_by_conf[bean]\n",
    "            \n",
    "        majo_preds = majority.argmax(axis=1)\n",
    "        macro = f1_score(y_test, majo_preds, average='macro') * 100\n",
    "        #print(f\"\\tFOLD: {fold} - {macro.:2f}\")\n",
    "        scores.append(macro)\n",
    "    mean_macro = np.mean(scores)\n",
    "    print(f\"\\tMacro - {mean_macro:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
