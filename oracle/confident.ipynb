{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(\"../analysis/utils/\")\n",
    "\n",
    "from utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"webkb\", \"20ng\"]#, \"acm\", \"reut\"]\n",
    "\n",
    "CLFS = [\"rep_bert\"]\n",
    "CLFS = [\"kpr\", \"ktr\", \"lpr\", \"ltr\", \"sfr\", \"stmk\", \"xfr\", \"xpr\", \"xtr\", \"kfr\", \"ktmk\", \"lfr\", \"ltmk\", \"spr\", \"str\", \"xlnet_softmax\", \"xtmk\", \"rep_bert\"]\n",
    "\n",
    "THRESHOLD = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_datasets = get_datasets(DATASETS, path=\"../../data/pd_datasets/__dset__.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf_beans(clf_probas, label):\n",
    "    predictions = clf_probas.argmax(axis=1)\n",
    "    confidence_freq = {}\n",
    "    hits = {}\n",
    "    # For each prediction\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        \n",
    "        # Getting the probability of the predicted class\n",
    "        probability = clf_probas[idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        # Adding the bean in confidence if is not there yet.\n",
    "        if bean not in confidence_freq:\n",
    "            confidence_freq[bean] = 0\n",
    "        confidence_freq[bean] += 1\n",
    "        # Veryfing if the predicted class was right.\n",
    "        if predicted_class == label[idx]:\n",
    "            if bean not in hits:\n",
    "                hits[bean] = 0\n",
    "            hits[bean] += 1\n",
    "    return confidence_freq, hits\n",
    "\n",
    "def get_miss_predictor(confidence_freq, hits, threshold=0.3):\n",
    "\n",
    "    predictor = {}\n",
    "    # For each confidence interval.\n",
    "    for bean in hits:\n",
    "        # Get the hit rate.\n",
    "        hits_rate = hits[bean] / confidence_freq[bean]\n",
    "        \n",
    "        if hits_rate < threshold:\n",
    "            predictor[bean] = True\n",
    "    return predictor\n",
    "\n",
    "def predict(X, estimator):\n",
    "    \n",
    "    estimates = []\n",
    "    predictions = X.argmax(axis=1)\n",
    "    # For each prediction.\n",
    "    for idx, predicted_class in enumerate(predictions):\n",
    "        probability = X[idx][predicted_class] * 10\n",
    "        bean = np.trunc(probability) / 10\n",
    "        bean = 0.9 if bean >= 1 else bean\n",
    "        # If this confidence has a miss rate greater than THRESHOLD (wether it is in the dictionary or not)\n",
    "        if bean in estimator:\n",
    "            estimates.append(0)\n",
    "        else:\n",
    "            estimates.append(1)\n",
    "    return np.array(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBKB\n",
      "\tKPR\n",
      "\t\tFOLD: 0 - Precision: 51.58 Recall: 22.58\n",
      "\t\tFOLD: 1 - Precision: 59.23 Recall: 35.0\n",
      "\t\tFOLD: 2 - Precision: 55.79 Recall: 22.84\n",
      "\t\tFOLD: 3 - Precision: 65.33 Recall: 22.48\n",
      "\t\tFOLD: 4 - Precision: 60.0 Recall: 25.4\n",
      "\t\tFOLD: 5 - Precision: 51.16 Recall: 20.85\n",
      "\t\tFOLD: 6 - Precision: 51.81 Recall: 19.2\n",
      "\t\tFOLD: 7 - Precision: 62.03 Recall: 20.16\n",
      "\t\tFOLD: 8 - Precision: 62.5 Recall: 32.56\n",
      "\t\tFOLD: 9 - Precision: 56.2 Recall: 34.38\n",
      "\tKTR\n",
      "\t\tFOLD: 0 - Precision: 63.96 Recall: 31.84\n",
      "\t\tFOLD: 1 - Precision: 70.67 Recall: 24.88\n",
      "\t\tFOLD: 2 - Precision: 55.14 Recall: 30.73\n",
      "\t\tFOLD: 3 - Precision: 61.46 Recall: 29.95\n",
      "\t\tFOLD: 4 - Precision: 56.25 Recall: 27.14\n",
      "\t\tFOLD: 5 - Precision: 64.04 Recall: 28.93\n",
      "\t\tFOLD: 6 - Precision: 45.95 Recall: 17.8\n",
      "\t\tFOLD: 7 - Precision: 70.83 Recall: 22.17\n",
      "\t\tFOLD: 8 - Precision: 60.22 Recall: 29.32\n",
      "\t\tFOLD: 9 - Precision: 57.84 Recall: 27.44\n",
      "\tLPR\n",
      "\t\tFOLD: 0 - Precision: 51.49 Recall: 23.32\n",
      "\t\tFOLD: 1 - Precision: 56.71 Recall: 41.15\n",
      "\t\tFOLD: 2 - Precision: 51.3 Recall: 37.98\n",
      "\t\tFOLD: 3 - Precision: 49.46 Recall: 20.0\n",
      "\t\tFOLD: 4 - Precision: 56.18 Recall: 19.31\n",
      "\t\tFOLD: 5 - Precision: 59.17 Recall: 29.58\n",
      "\t\tFOLD: 6 - Precision: 61.46 Recall: 23.89\n",
      "\t\tFOLD: 7 - Precision: 60.0 Recall: 24.59\n",
      "\t\tFOLD: 8 - Precision: 47.92 Recall: 20.44\n",
      "\t\tFOLD: 9 - Precision: 59.09 Recall: 26.86\n",
      "\tLTR\n",
      "\t\tFOLD: 0 - Precision: 52.17 Recall: 9.16\n",
      "\t\tFOLD: 1 - Precision: 64.0 Recall: 10.81\n",
      "\t\tFOLD: 2 - Precision: 71.43 Recall: 6.37\n",
      "\t\tFOLD: 3 - Precision: 75.0 Recall: 5.88\n",
      "\t\tFOLD: 4 - Precision: 60.0 Recall: 6.38\n",
      "\t\tFOLD: 5 - Precision: 44.44 Recall: 5.71\n",
      "\t\tFOLD: 6 - Precision: 63.64 Recall: 5.11\n",
      "\t\tFOLD: 7 - Precision: 50.0 Recall: 4.14\n",
      "\t\tFOLD: 8 - Precision: 69.23 Recall: 7.38\n",
      "\t\tFOLD: 9 - Precision: 66.67 Recall: 8.05\n",
      "\tSFR\n",
      "\t\tFOLD: 0 - Precision: 53.85 Recall: 6.51\n",
      "\t\tFOLD: 1 - Precision: 60.0 Recall: 5.56\n",
      "\t\tFOLD: 2 - Precision: 43.75 Recall: 3.41\n",
      "\t\tFOLD: 3 - Precision: 55.56 Recall: 8.24\n",
      "\t\tFOLD: 4 - Precision: 50.0 Recall: 5.1\n",
      "\t\tFOLD: 5 - Precision: 60.0 Recall: 2.96\n",
      "\t\tFOLD: 6 - Precision: 46.67 Recall: 3.61\n",
      "\t\tFOLD: 7 - Precision: 60.0 Recall: 7.08\n",
      "\t\tFOLD: 8 - Precision: 50.0 Recall: 4.73\n",
      "\t\tFOLD: 9 - Precision: 55.56 Recall: 4.98\n",
      "\tSTMK\n",
      "\t\tFOLD: 0 - Precision: 50.0 Recall: 6.63\n",
      "\t\tFOLD: 1 - Precision: 81.82 Recall: 4.79\n",
      "\t\tFOLD: 2 - Precision: 55.0 Recall: 5.73\n",
      "\t\tFOLD: 3 - Precision: 50.0 Recall: 7.18\n",
      "\t\tFOLD: 4 - Precision: 57.14 Recall: 4.06\n",
      "\t\tFOLD: 5 - Precision: 44.44 Recall: 4.65\n",
      "\t\tFOLD: 6 - Precision: 64.71 Recall: 6.01\n",
      "\t\tFOLD: 7 - Precision: 72.22 Recall: 6.63\n",
      "\t\tFOLD: 8 - Precision: 55.0 Recall: 6.32\n",
      "\t\tFOLD: 9 - Precision: 54.55 Recall: 6.42\n",
      "\tXFR\n",
      "\t\tFOLD: 0 - Precision: 66.67 Recall: 25.24\n",
      "\t\tFOLD: 1 - Precision: 65.75 Recall: 23.19\n",
      "\t\tFOLD: 2 - Precision: 73.77 Recall: 21.23\n",
      "\t\tFOLD: 3 - Precision: 58.23 Recall: 22.77\n",
      "\t\tFOLD: 4 - Precision: 53.26 Recall: 25.0\n",
      "\t\tFOLD: 5 - Precision: 67.9 Recall: 26.83\n",
      "\t\tFOLD: 6 - Precision: 54.64 Recall: 27.18\n",
      "\t\tFOLD: 7 - Precision: 52.63 Recall: 25.25\n",
      "\t\tFOLD: 8 - Precision: 56.76 Recall: 23.46\n",
      "\t\tFOLD: 9 - Precision: 60.87 Recall: 21.21\n",
      "\tXPR\n",
      "\t\tFOLD: 0 - Precision: 43.56 Recall: 27.5\n",
      "\t\tFOLD: 1 - Precision: 73.33 Recall: 17.93\n",
      "\t\tFOLD: 2 - Precision: 55.26 Recall: 11.54\n",
      "\t\tFOLD: 3 - Precision: 52.83 Recall: 15.3\n",
      "\t\tFOLD: 4 - Precision: 56.41 Recall: 11.11\n",
      "\t\tFOLD: 5 - Precision: 55.0 Recall: 12.64\n",
      "\t\tFOLD: 6 - Precision: 57.14 Recall: 14.55\n",
      "\t\tFOLD: 7 - Precision: 54.29 Recall: 11.24\n",
      "\t\tFOLD: 8 - Precision: 44.74 Recall: 10.56\n",
      "\t\tFOLD: 9 - Precision: 62.75 Recall: 17.78\n",
      "\tXTR\n",
      "\t\tFOLD: 0 - Precision: 68.18 Recall: 10.27\n",
      "\t\tFOLD: 1 - Precision: 60.61 Recall: 13.99\n",
      "\t\tFOLD: 2 - Precision: 70.45 Recall: 20.95\n",
      "\t\tFOLD: 3 - Precision: 64.0 Recall: 12.03\n",
      "\t\tFOLD: 4 - Precision: 51.22 Recall: 15.44\n",
      "\t\tFOLD: 5 - Precision: 66.67 Recall: 20.74\n",
      "\t\tFOLD: 6 - Precision: 58.82 Recall: 16.0\n",
      "\t\tFOLD: 7 - Precision: 66.67 Recall: 11.76\n",
      "\t\tFOLD: 8 - Precision: 64.29 Recall: 16.51\n",
      "\t\tFOLD: 9 - Precision: 61.54 Recall: 18.46\n",
      "\tKFR\n",
      "\t\tFOLD: 0 - Precision: 68.0 Recall: 8.9\n",
      "\t\tFOLD: 1 - Precision: 55.17 Recall: 8.21\n",
      "\t\tFOLD: 2 - Precision: 51.72 Recall: 7.5\n",
      "\t\tFOLD: 3 - Precision: 65.38 Recall: 9.5\n",
      "\t\tFOLD: 4 - Precision: 60.0 Recall: 10.94\n",
      "\t\tFOLD: 5 - Precision: 71.79 Recall: 14.43\n",
      "\t\tFOLD: 6 - Precision: 50.0 Recall: 5.41\n",
      "\t\tFOLD: 7 - Precision: 45.71 Recall: 8.7\n",
      "\t\tFOLD: 8 - Precision: 50.88 Recall: 18.71\n",
      "\t\tFOLD: 9 - Precision: 65.85 Recall: 13.64\n",
      "\tKTMK\n",
      "\t\tFOLD: 0 - Precision: 50.98 Recall: 14.36\n",
      "\t\tFOLD: 1 - Precision: 76.6 Recall: 17.82\n",
      "\t\tFOLD: 2 - Precision: 61.9 Recall: 14.29\n",
      "\t\tFOLD: 3 - Precision: 57.35 Recall: 20.1\n",
      "\t\tFOLD: 4 - Precision: 56.38 Recall: 27.18\n",
      "\t\tFOLD: 5 - Precision: 76.09 Recall: 19.55\n",
      "\t\tFOLD: 6 - Precision: 63.27 Recall: 17.61\n",
      "\t\tFOLD: 7 - Precision: 52.75 Recall: 24.12\n",
      "\t\tFOLD: 8 - Precision: 60.0 Recall: 14.04\n",
      "\t\tFOLD: 9 - Precision: 58.06 Recall: 29.19\n",
      "\tLFR\n",
      "\t\tFOLD: 0 - Precision: 50.65 Recall: 20.63\n",
      "\t\tFOLD: 1 - Precision: 55.77 Recall: 14.65\n",
      "\t\tFOLD: 2 - Precision: 64.81 Recall: 16.91\n",
      "\t\tFOLD: 3 - Precision: 51.09 Recall: 25.41\n",
      "\t\tFOLD: 4 - Precision: 53.62 Recall: 19.27\n",
      "\t\tFOLD: 5 - Precision: 57.14 Recall: 25.0\n",
      "\t\tFOLD: 6 - Precision: 58.49 Recall: 16.32\n",
      "\t\tFOLD: 7 - Precision: 55.7 Recall: 22.11\n",
      "\t\tFOLD: 8 - Precision: 48.68 Recall: 22.84\n",
      "\t\tFOLD: 9 - Precision: 61.73 Recall: 24.88\n",
      "\tLTMK\n",
      "\t\tFOLD: 0 - Precision: 57.5 Recall: 12.85\n",
      "\t\tFOLD: 1 - Precision: 46.88 Recall: 7.77\n",
      "\t\tFOLD: 2 - Precision: 48.65 Recall: 9.89\n",
      "\t\tFOLD: 3 - Precision: 55.88 Recall: 10.44\n",
      "\t\tFOLD: 4 - Precision: 55.88 Recall: 9.45\n",
      "\t\tFOLD: 5 - Precision: 70.97 Recall: 13.02\n",
      "\t\tFOLD: 6 - Precision: 58.33 Recall: 11.29\n",
      "\t\tFOLD: 7 - Precision: 40.0 Recall: 8.16\n",
      "\t\tFOLD: 8 - Precision: 40.62 Recall: 8.33\n",
      "\t\tFOLD: 9 - Precision: 73.81 Recall: 16.23\n",
      "\tSPR\n",
      "\t\tFOLD: 0 - Precision: 67.65 Recall: 10.31\n",
      "\t\tFOLD: 1 - Precision: 60.71 Recall: 6.97\n",
      "\t\tFOLD: 2 - Precision: 65.79 Recall: 11.52\n",
      "\t\tFOLD: 3 - Precision: 57.69 Recall: 6.2\n",
      "\t\tFOLD: 4 - Precision: 54.84 Recall: 6.75\n",
      "\t\tFOLD: 5 - Precision: 60.71 Recall: 7.11\n",
      "\t\tFOLD: 6 - Precision: 57.58 Recall: 7.69\n",
      "\t\tFOLD: 7 - Precision: 58.06 Recall: 7.56\n",
      "\t\tFOLD: 8 - Precision: 67.65 Recall: 10.41\n",
      "\t\tFOLD: 9 - Precision: 63.89 Recall: 10.04\n",
      "\tSTR\n",
      "\t\tFOLD: 0 - Precision: 50.0 Recall: 3.38\n",
      "\t\tFOLD: 1 - Precision: 66.67 Recall: 2.45\n",
      "\t\tFOLD: 2 - Precision: 57.14 Recall: 2.6\n",
      "\t\tFOLD: 3 - Precision: 50.0 Recall: 1.92\n",
      "\t\tFOLD: 4 - Precision: 28.57 Recall: 1.35\n",
      "\t\tFOLD: 5 - Precision: 37.5 Recall: 1.91\n",
      "\t\tFOLD: 6 - Precision: 90.0 Recall: 5.73\n",
      "\t\tFOLD: 7 - Precision: 100.0 Recall: 0.64\n",
      "\t\tFOLD: 8 - Precision: 66.67 Recall: 1.49\n",
      "\t\tFOLD: 9 - Precision: 100.0 Recall: 1.29\n",
      "\tXLNET_SOFTMAX\n",
      "\t\tFOLD: 0 - Precision: 60.0 Recall: 2.63\n",
      "\t\tFOLD: 1 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 2 - Precision: 54.55 Recall: 4.55\n",
      "\t\tFOLD: 3 - Precision: 33.33 Recall: 0.71\n",
      "\t\tFOLD: 4 - Precision: 50.0 Recall: 2.27\n",
      "\t\tFOLD: 5 - Precision: 50.0 Recall: 0.9\n",
      "\t\tFOLD: 6 - Precision: 100.0 Recall: 2.4\n",
      "\t\tFOLD: 7 - Precision: 50.0 Recall: 0.84\n",
      "\t\tFOLD: 8 - Precision: 33.33 Recall: 0.83\n",
      "\t\tFOLD: 9 - Precision: 14.29 Recall: 0.78\n",
      "\tXTMK\n",
      "\t\tFOLD: 0 - Precision: 50.63 Recall: 25.64\n",
      "\t\tFOLD: 1 - Precision: 57.69 Recall: 25.28\n",
      "\t\tFOLD: 2 - Precision: 55.56 Recall: 43.1\n",
      "\t\tFOLD: 3 - Precision: 58.75 Recall: 27.17\n",
      "\t\tFOLD: 4 - Precision: 63.33 Recall: 22.09\n",
      "\t\tFOLD: 5 - Precision: 54.32 Recall: 28.95\n",
      "\t\tFOLD: 6 - Precision: 53.16 Recall: 24.42\n",
      "\t\tFOLD: 7 - Precision: 58.82 Recall: 21.28\n",
      "\t\tFOLD: 8 - Precision: 50.0 Recall: 28.48\n",
      "\t\tFOLD: 9 - Precision: 50.62 Recall: 24.55\n",
      "\tREP_BERT\n",
      "\t\tFOLD: 0 - Precision: 55.0 Recall: 11.83\n",
      "\t\tFOLD: 1 - Precision: 45.95 Recall: 17.71\n",
      "\t\tFOLD: 2 - Precision: 50.0 Recall: 9.8\n",
      "\t\tFOLD: 3 - Precision: 87.5 Recall: 6.73\n",
      "\t\tFOLD: 4 - Precision: 66.67 Recall: 16.22\n",
      "\t\tFOLD: 5 - Precision: 45.45 Recall: 13.76\n",
      "\t\tFOLD: 6 - Precision: 47.83 Recall: 14.47\n",
      "\t\tFOLD: 7 - Precision: 28.0 Recall: 8.33\n",
      "\t\tFOLD: 8 - Precision: 58.82 Recall: 11.36\n",
      "\t\tFOLD: 9 - Precision: 61.54 Recall: 7.77\n",
      "20NG\n",
      "\tKPR\n",
      "\t\tFOLD: 0 - Precision: 71.43 Recall: 26.88\n",
      "\t\tFOLD: 1 - Precision: 57.71 Recall: 27.75\n",
      "\t\tFOLD: 2 - Precision: 63.19 Recall: 32.95\n",
      "\t\tFOLD: 3 - Precision: 62.28 Recall: 32.81\n",
      "\t\tFOLD: 4 - Precision: 68.65 Recall: 33.33\n",
      "\t\tFOLD: 5 - Precision: 71.23 Recall: 29.8\n",
      "\t\tFOLD: 6 - Precision: 63.48 Recall: 31.83\n",
      "\t\tFOLD: 7 - Precision: 64.97 Recall: 36.36\n",
      "\t\tFOLD: 8 - Precision: 59.41 Recall: 29.45\n",
      "\t\tFOLD: 9 - Precision: 60.41 Recall: 33.9\n",
      "\tKTR\n",
      "\t\tFOLD: 0 - Precision: 65.22 Recall: 16.13\n",
      "\t\tFOLD: 1 - Precision: 47.06 Recall: 30.48\n",
      "\t\tFOLD: 2 - Precision: 49.5 Recall: 33.9\n",
      "\t\tFOLD: 3 - Precision: 64.29 Recall: 12.63\n",
      "\t\tFOLD: 4 - Precision: 95.45 Recall: 7.29\n",
      "\t\tFOLD: 5 - Precision: 65.22 Recall: 16.48\n",
      "\t\tFOLD: 6 - Precision: 75.0 Recall: 12.72\n",
      "\t\tFOLD: 7 - Precision: 77.78 Recall: 4.9\n",
      "\t\tFOLD: 8 - Precision: 60.0 Recall: 2.06\n",
      "\t\tFOLD: 9 - Precision: 73.02 Recall: 15.08\n",
      "\tLPR\n",
      "\t\tFOLD: 0 - Precision: 64.84 Recall: 28.23\n",
      "\t\tFOLD: 1 - Precision: 60.24 Recall: 23.36\n",
      "\t\tFOLD: 2 - Precision: 61.46 Recall: 28.37\n",
      "\t\tFOLD: 3 - Precision: 68.42 Recall: 32.34\n",
      "\t\tFOLD: 4 - Precision: 60.0 Recall: 27.65\n",
      "\t\tFOLD: 5 - Precision: 70.69 Recall: 22.53\n",
      "\t\tFOLD: 6 - Precision: 63.83 Recall: 28.04\n",
      "\t\tFOLD: 7 - Precision: 63.83 Recall: 30.77\n",
      "\t\tFOLD: 8 - Precision: 55.29 Recall: 22.38\n",
      "\t\tFOLD: 9 - Precision: 70.8 Recall: 34.78\n",
      "\tLTR\n",
      "\t\tFOLD: 0 - Precision: 56.06 Recall: 38.95\n",
      "\t\tFOLD: 1 - Precision: 70.69 Recall: 17.98\n",
      "\t\tFOLD: 2 - Precision: 56.1 Recall: 37.91\n",
      "\t\tFOLD: 3 - Precision: 55.26 Recall: 28.77\n",
      "\t\tFOLD: 4 - Precision: 64.0 Recall: 15.02\n",
      "\t\tFOLD: 5 - Precision: 59.65 Recall: 36.17\n",
      "\t\tFOLD: 6 - Precision: 88.89 Recall: 3.85\n",
      "\t\tFOLD: 7 - Precision: 75.0 Recall: 20.45\n",
      "\t\tFOLD: 8 - Precision: 60.31 Recall: 36.24\n",
      "\t\tFOLD: 9 - Precision: 63.83 Recall: 13.22\n",
      "\tSFR\n",
      "\t\tFOLD: 0 - Precision: 81.25 Recall: 3.64\n",
      "\t\tFOLD: 1 - Precision: 84.62 Recall: 2.78\n",
      "\t\tFOLD: 2 - Precision: 62.5 Recall: 1.39\n",
      "\t\tFOLD: 3 - Precision: 66.67 Recall: 2.22\n",
      "\t\tFOLD: 4 - Precision: 100.0 Recall: 2.43\n",
      "\t\tFOLD: 5 - Precision: 91.67 Recall: 3.21\n",
      "\t\tFOLD: 6 - Precision: 45.45 Recall: 1.36\n",
      "\t\tFOLD: 7 - Precision: 63.64 Recall: 1.83\n",
      "\t\tFOLD: 8 - Precision: 100.0 Recall: 0.53\n",
      "\t\tFOLD: 9 - Precision: 90.91 Recall: 2.62\n",
      "\tSTMK\n",
      "\t\tFOLD: 0 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 1 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 2 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 3 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 4 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 5 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 6 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 7 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 8 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 9 - Precision: 100.0 Recall: 0.0\n",
      "\tXFR\n",
      "\t\tFOLD: 0 - Precision: 59.09 Recall: 53.69\n",
      "\t\tFOLD: 1 - Precision: 58.13 Recall: 44.09\n",
      "\t\tFOLD: 2 - Precision: 60.07 Recall: 47.31\n",
      "\t\tFOLD: 3 - Precision: 65.69 Recall: 47.37\n",
      "\t\tFOLD: 4 - Precision: 59.93 Recall: 45.92\n",
      "\t\tFOLD: 5 - Precision: 62.35 Recall: 44.51\n",
      "\t\tFOLD: 6 - Precision: 60.44 Recall: 44.96\n",
      "\t\tFOLD: 7 - Precision: 65.03 Recall: 50.0\n",
      "\t\tFOLD: 8 - Precision: 64.05 Recall: 49.12\n",
      "\t\tFOLD: 9 - Precision: 66.32 Recall: 48.34\n",
      "\tXPR\n",
      "\t\tFOLD: 0 - Precision: 73.83 Recall: 32.51\n",
      "\t\tFOLD: 1 - Precision: 62.6 Recall: 28.21\n",
      "\t\tFOLD: 2 - Precision: 65.79 Recall: 28.41\n",
      "\t\tFOLD: 3 - Precision: 66.67 Recall: 26.4\n",
      "\t\tFOLD: 4 - Precision: 68.7 Recall: 29.81\n",
      "\t\tFOLD: 5 - Precision: 66.67 Recall: 31.97\n",
      "\t\tFOLD: 6 - Precision: 61.17 Recall: 23.77\n",
      "\t\tFOLD: 7 - Precision: 62.5 Recall: 25.49\n",
      "\t\tFOLD: 8 - Precision: 71.68 Recall: 32.27\n",
      "\t\tFOLD: 9 - Precision: 69.75 Recall: 29.33\n",
      "\tXTR\n",
      "\t\tFOLD: 0 - Precision: 61.64 Recall: 52.69\n",
      "\t\tFOLD: 1 - Precision: 59.6 Recall: 45.5\n",
      "\t\tFOLD: 2 - Precision: 60.47 Recall: 49.04\n",
      "\t\tFOLD: 3 - Precision: 73.2 Recall: 29.02\n",
      "\t\tFOLD: 4 - Precision: 83.08 Recall: 14.96\n",
      "\t\tFOLD: 5 - Precision: 61.11 Recall: 49.44\n",
      "\t\tFOLD: 6 - Precision: 56.44 Recall: 40.71\n",
      "\t\tFOLD: 7 - Precision: 72.0 Recall: 31.27\n",
      "\t\tFOLD: 8 - Precision: 62.18 Recall: 46.52\n",
      "\t\tFOLD: 9 - Precision: 84.06 Recall: 15.26\n",
      "\tKFR\n",
      "\t\tFOLD: 0 - Precision: 59.57 Recall: 50.0\n",
      "\t\tFOLD: 1 - Precision: 63.35 Recall: 45.88\n",
      "\t\tFOLD: 2 - Precision: 59.55 Recall: 47.32\n",
      "\t\tFOLD: 3 - Precision: 58.16 Recall: 43.62\n",
      "\t\tFOLD: 4 - Precision: 61.31 Recall: 50.54\n",
      "\t\tFOLD: 5 - Precision: 61.66 Recall: 46.02\n",
      "\t\tFOLD: 6 - Precision: 63.16 Recall: 48.14\n",
      "\t\tFOLD: 7 - Precision: 60.07 Recall: 47.49\n",
      "\t\tFOLD: 8 - Precision: 59.14 Recall: 44.59\n",
      "\t\tFOLD: 9 - Precision: 63.64 Recall: 52.55\n",
      "\tKTMK\n",
      "\t\tFOLD: 0 - Precision: 66.35 Recall: 43.12\n",
      "\t\tFOLD: 1 - Precision: 61.73 Recall: 24.88\n",
      "\t\tFOLD: 2 - Precision: 66.28 Recall: 30.32\n",
      "\t\tFOLD: 3 - Precision: 64.37 Recall: 31.64\n",
      "\t\tFOLD: 4 - Precision: 70.45 Recall: 33.88\n",
      "\t\tFOLD: 5 - Precision: 60.0 Recall: 30.91\n",
      "\t\tFOLD: 6 - Precision: 58.11 Recall: 25.29\n",
      "\t\tFOLD: 7 - Precision: 65.66 Recall: 33.85\n",
      "\t\tFOLD: 8 - Precision: 56.84 Recall: 31.03\n",
      "\t\tFOLD: 9 - Precision: 65.38 Recall: 34.69\n",
      "\tLFR\n",
      "\t\tFOLD: 0 - Precision: 61.36 Recall: 32.43\n",
      "\t\tFOLD: 1 - Precision: 59.38 Recall: 31.4\n",
      "\t\tFOLD: 2 - Precision: 57.2 Recall: 41.37\n",
      "\t\tFOLD: 3 - Precision: 64.39 Recall: 24.22\n",
      "\t\tFOLD: 4 - Precision: 59.27 Recall: 45.66\n",
      "\t\tFOLD: 5 - Precision: 64.74 Recall: 37.61\n",
      "\t\tFOLD: 6 - Precision: 63.4 Recall: 27.87\n",
      "\t\tFOLD: 7 - Precision: 64.4 Recall: 34.94\n",
      "\t\tFOLD: 8 - Precision: 57.47 Recall: 42.02\n",
      "\t\tFOLD: 9 - Precision: 60.47 Recall: 44.07\n",
      "\tLTMK\n",
      "\t\tFOLD: 0 - Precision: 54.29 Recall: 26.39\n",
      "\t\tFOLD: 1 - Precision: 68.52 Recall: 18.88\n",
      "\t\tFOLD: 2 - Precision: 59.42 Recall: 22.16\n",
      "\t\tFOLD: 3 - Precision: 56.47 Recall: 26.97\n",
      "\t\tFOLD: 4 - Precision: 52.22 Recall: 26.7\n",
      "\t\tFOLD: 5 - Precision: 63.79 Recall: 23.42\n",
      "\t\tFOLD: 6 - Precision: 65.31 Recall: 18.93\n",
      "\t\tFOLD: 7 - Precision: 53.16 Recall: 23.86\n",
      "\t\tFOLD: 8 - Precision: 57.45 Recall: 31.58\n",
      "\t\tFOLD: 9 - Precision: 62.73 Recall: 35.57\n",
      "\tSPR\n",
      "\t\tFOLD: 0 - Precision: 58.33 Recall: 6.51\n",
      "\t\tFOLD: 1 - Precision: 53.85 Recall: 6.7\n",
      "\t\tFOLD: 2 - Precision: 57.14 Recall: 7.34\n",
      "\t\tFOLD: 3 - Precision: 61.9 Recall: 5.99\n",
      "\t\tFOLD: 4 - Precision: 81.82 Recall: 7.89\n",
      "\t\tFOLD: 5 - Precision: 69.57 Recall: 8.56\n",
      "\t\tFOLD: 6 - Precision: 51.85 Recall: 6.57\n",
      "\t\tFOLD: 7 - Precision: 65.38 Recall: 8.54\n",
      "\t\tFOLD: 8 - Precision: 70.0 Recall: 6.36\n",
      "\t\tFOLD: 9 - Precision: 72.41 Recall: 9.05\n",
      "\tSTR\n",
      "\t\tFOLD: 0 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 1 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 2 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 3 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 4 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 5 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 6 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 7 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 8 - Precision: 100.0 Recall: 0.0\n",
      "\t\tFOLD: 9 - Precision: 100.0 Recall: 0.0\n",
      "\tXLNET_SOFTMAX\n",
      "\t\tFOLD: 0 - Precision: 68.26 Recall: 67.09\n",
      "\t\tFOLD: 1 - Precision: 68.34 Recall: 62.81\n",
      "\t\tFOLD: 2 - Precision: 67.32 Recall: 68.65\n",
      "\t\tFOLD: 3 - Precision: 70.11 Recall: 67.02\n",
      "\t\tFOLD: 4 - Precision: 65.88 Recall: 67.88\n",
      "\t\tFOLD: 5 - Precision: 64.75 Recall: 66.81\n",
      "\t\tFOLD: 6 - Precision: 69.34 Recall: 63.94\n",
      "\t\tFOLD: 7 - Precision: 65.18 Recall: 65.6\n",
      "\t\tFOLD: 8 - Precision: 62.33 Recall: 59.16\n",
      "\t\tFOLD: 9 - Precision: 69.18 Recall: 47.83\n",
      "\tXTMK\n",
      "\t\tFOLD: 0 - Precision: 61.24 Recall: 46.75\n",
      "\t\tFOLD: 1 - Precision: 58.33 Recall: 42.21\n",
      "\t\tFOLD: 2 - Precision: 72.18 Recall: 47.29\n",
      "\t\tFOLD: 3 - Precision: 54.9 Recall: 43.98\n",
      "\t\tFOLD: 4 - Precision: 56.2 Recall: 40.1\n",
      "\t\tFOLD: 5 - Precision: 67.67 Recall: 51.14\n",
      "\t\tFOLD: 6 - Precision: 55.56 Recall: 38.46\n",
      "\t\tFOLD: 7 - Precision: 53.64 Recall: 42.63\n",
      "\t\tFOLD: 8 - Precision: 62.07 Recall: 48.39\n",
      "\t\tFOLD: 9 - Precision: 70.54 Recall: 45.96\n",
      "\tREP_BERT\n",
      "\t\tFOLD: 0 - Precision: 59.29 Recall: 32.37\n",
      "\t\tFOLD: 1 - Precision: 60.53 Recall: 38.33\n",
      "\t\tFOLD: 2 - Precision: 61.11 Recall: 45.83\n",
      "\t\tFOLD: 3 - Precision: 67.07 Recall: 23.71\n",
      "\t\tFOLD: 4 - Precision: 57.76 Recall: 32.52\n",
      "\t\tFOLD: 5 - Precision: 64.67 Recall: 46.63\n",
      "\t\tFOLD: 6 - Precision: 62.4 Recall: 33.48\n",
      "\t\tFOLD: 7 - Precision: 64.6 Recall: 36.5\n",
      "\t\tFOLD: 8 - Precision: 57.72 Recall: 31.84\n",
      "\t\tFOLD: 9 - Precision: 61.36 Recall: 33.2\n"
     ]
    }
   ],
   "source": [
    "for dset in DATASETS:\n",
    "    print(f\"{dset.upper()}\")\n",
    "    for clf in CLFS:\n",
    "        print(f\"\\t{clf.upper()}\")\n",
    "        for fold in np.arange(10):\n",
    "            probs_dir = f\"/home/welton/data/clfs_output/split_10/{dset}/10_folds/{clf}/{fold}\"\n",
    "            # Loading probabilities.\n",
    "            X_train = np.load(f\"{probs_dir}/train.npz\")[\"X_train\"]\n",
    "            labels_dir = f\"/home/welton/data/datasets/labels/split_10/{dset}/{fold}\"\n",
    "            train_labels = np.load(f\"{labels_dir}/train.npy\")\n",
    "            \n",
    "            X_test = np.load(f\"{probs_dir}/test.npz\")[\"X_test\"]\n",
    "            \n",
    "            # Building error estimator.\n",
    "            confidence_freq, hits = build_clf_beans(X_train, train_labels)\n",
    "            estimator = get_miss_predictor(confidence_freq, hits, THRESHOLD)\n",
    "            \n",
    "            # Applying estimator on train and test.\n",
    "            train_est = predict(X_train, estimator)\n",
    "            test_est = predict(X_test, estimator)\n",
    "            \n",
    "            # Comparing this strategy with \n",
    "            y_true = np.load(f\"/home/welton/data/oracle/upper_bound/{dset}/{clf}/{fold}/test.npz\")[\"y\"]\n",
    "            prec = np.round(precision_score(y_true, test_est, zero_division=1, pos_label=0) * 100, decimals=2)\n",
    "            rec = np.round(recall_score(y_true, test_est, pos_label=0) * 100, decimals=2)\n",
    "            print(f\"\\t\\tFOLD: {fold} - Precision: {prec} Recall: {rec}\")\n",
    "            output_dir = f\"/home/welton/data/oracle/hits_rate/{THRESHOLD}/{dset}/{clf}/{fold}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            np.savez(f\"{output_dir}/test\", y=test_est)\n",
    "            np.savez(f\"{output_dir}/train\", y=train_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.load(\"../../data/oracle/upper_bound/webkb/lfr/0/test.npz\").keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([   3, 1889])), (array([0, 1]), array([   34, 16920])))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.1/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.1/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([  63, 1829])), (array([0, 1]), array([  701, 16253])))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.2/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.2/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1]), array([ 196, 1696])), (array([0, 1]), array([ 1904, 15050])))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(np.load(\"../../data/oracle/hits_rate/0.3/20ng/xlnet_softmax/0/test.npz\")['y'], return_counts=True),\n",
    "np.unique(np.load(\"../../data/oracle/hits_rate/0.3/20ng/xlnet_softmax/0/train.npz\")['y'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
