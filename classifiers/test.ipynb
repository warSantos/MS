{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/welton/project/.env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.models.models import get_classifier\n",
    "from src.models.optimization import execute_optimization\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from optuna.exceptions import ExperimentalWarning\n",
    "from optuna.logging import set_verbosity, WARNING\n",
    "set_verbosity(WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, _ = get_classifier(\"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 200,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': -1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'sag',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.7, dual=True, max_iter=200, n_jobs=-1, random_state=42,\n",
       "                   solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.7, dual=True, max_iter=200, n_jobs=-1, random_state=42,\n",
       "                   solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.7, dual=True, max_iter=200, n_jobs=-1, random_state=42,\n",
       "                   solver='sag')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(**{'C': 0.7, 'dual': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.7,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 200,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': -1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'sag',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_name = \"knn\"\n",
    "calib_method = \"isotonic\"\n",
    "clf_n_jobs = 20\n",
    "opt_n_jobs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"/home/welton/data/stacking/stacking_output/20ng/10_folds/logistic_regression/dist/fold_0/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', StandardScaler(with_mean=False)),\n",
       "  ('classifier',\n",
       "   LogisticRegression(C=11.279016534699569, n_jobs=1, random_state=42,\n",
       "                      solver='sag'))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(with_mean=False),\n",
       " 'classifier': LogisticRegression(C=11.279016534699569, n_jobs=1, random_state=42,\n",
       "                    solver='sag'),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': False,\n",
       " 'scaler__with_std': True,\n",
       " 'classifier__C': 11.279016534699569,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': False,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__l1_ratio': None,\n",
       " 'classifier__max_iter': 100,\n",
       " 'classifier__multi_class': 'auto',\n",
       " 'classifier__n_jobs': 1,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__random_state': 42,\n",
       " 'classifier__solver': 'sag',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 0 - Opt: 0.7445800425975998, Christian: 0.7351208512160738, Opt and Calib: 0.7386552971041764, Just Calib: 0.7556071200950986\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 1 - Opt: 0.7005408474723874, Christian: 0.6964692825788283, Opt and Calib: 0.6891532361958452, Just Calib: 0.6686931326103401\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 2 - Opt: 0.6449280467505575, Christian: 0.6524161976397361, Opt and Calib: 0.6445177850106546, Just Calib: 0.6564007616127377\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 3 - Opt: 0.6568504450761238, Christian: 0.6562867065228761, Opt and Calib: 0.6630046987468281, Just Calib: 0.6554586321109649\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 4 - Opt: 0.6465813632323459, Christian: 0.6591053830406729, Opt and Calib: 0.6605779481719339, Just Calib: 0.6580250942911771\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 5 - Opt: 0.6461622164945654, Christian: 0.6665335891871764, Opt and Calib: 0.6759547243080662, Just Calib: 0.6777812063386562\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 6 - Opt: 0.6801133031295422, Christian: 0.6648719677292261, Opt and Calib: 0.6915042828156028, Just Calib: 0.6537487158893337\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 7 - Opt: 0.7066741618088643, Christian: 0.7085282048112618, Opt and Calib: 0.6942082828342073, Just Calib: 0.702491437987834\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 8 - Opt: 0.7398091892760309, Christian: 0.7567506377908669, Opt and Calib: 0.7638383604862593, Just Calib: 0.7513684689968336\n",
      "\tExecuting model...\n",
      "\tExecuting model...\n",
      "FOLD: 9 - Opt: 0.7238877129871248, Christian: 0.7204925929971698, Opt and Calib: 0.7202418792432231, Just Calib: 0.7238741188974821\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for fold in np.arange(10):\n",
    "    \n",
    "    train_load = np.load(f\"/home/welton/data/representations/webkb/10_folds/fr/{fold}/train.npz\", allow_pickle=True)\n",
    "    test_load = np.load(f\"/home/welton/data/representations/webkb/10_folds/fr/{fold}/test.npz\", allow_pickle=True)\n",
    "\n",
    "    X_train, y_train = train_load[\"X_train\"].tolist().toarray(), train_load[\"y_train\"]\n",
    "    X_test, y_test = test_load[\"X_test\"].tolist().toarray(), test_load[\"y_test\"]\n",
    "\n",
    "    output_dir = f\"data/{estimator_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    optuna_search = execute_optimization(estimator_name, output_dir, X_train, y_train, clf_n_jobs=clf_n_jobs, opt_n_jobs=opt_n_jobs)\n",
    "\n",
    "    preds = optuna_search.best_estimator_.predict(X_test)\n",
    "    opt = f1_score(y_test, preds, average=\"macro\")\n",
    "\n",
    "    probas = np.load(f\"/home/welton/data/clfs_output/split_10/webkb/10_folds/kfr/{fold}/test.npz\")[\"X_test\"]\n",
    "    chr = f1_score(y_test, probas.argmax(axis=1), average=\"macro\")\n",
    "\n",
    "    X_train_sub, X_eval, y_train_sub, y_eval = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "    \n",
    "    output_calib_dir = f\"data/{estimator_name}_calib/{calib_method}\"\n",
    "    os.makedirs(output_calib_dir, exist_ok=True)\n",
    "    optuna_search_calib = execute_optimization(estimator_name, output_calib_dir, X_train_sub, y_train_sub, clf_n_jobs=clf_n_jobs, opt_n_jobs=opt_n_jobs)\n",
    "\n",
    "    calibrated = CalibratedClassifierCV(optuna_search_calib.best_estimator_, method=calib_method, cv=\"prefit\", n_jobs=10)\n",
    "    calibrated.fit(X_eval, y_eval)\n",
    "    calib_preds = calibrated.predict(X_test)\n",
    "    opt_calib = f1_score(y_test, calib_preds, average=\"macro\")\n",
    "    \n",
    "    clf, _ = get_classifier(estimator_name, n_jobs=10)\n",
    "    clf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    just_calibrated = CalibratedClassifierCV(clf, method=calib_method, cv=\"prefit\", n_jobs=10)\n",
    "    just_calibrated.fit(X_eval, y_eval)\n",
    "    just_calib_preds = just_calibrated.predict(X_test)\n",
    "    just_calib = f1_score(y_test, just_calib_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"FOLD: {fold} - Opt: {opt}, Christian: {chr}, Opt and Calib: {opt_calib}, Just Calib: {just_calib}\")\n",
    "    scores.append([fold, opt, chr, opt_calib, just_calib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5       , 0.68901273, 0.69165754, 0.69416565, 0.69034487])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(scores)\n",
    "np.save(f\"data/calib_depure/{estimator_name}\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.74458004, 0.73512085, 0.7386553 , 0.75560712],\n",
       "       [1.        , 0.70054085, 0.69646928, 0.68915324, 0.66869313],\n",
       "       [2.        , 0.64492805, 0.6524162 , 0.64451779, 0.65640076],\n",
       "       [3.        , 0.65685045, 0.65628671, 0.6630047 , 0.65545863],\n",
       "       [4.        , 0.64658136, 0.65910538, 0.66057795, 0.65802509],\n",
       "       [5.        , 0.64616222, 0.66653359, 0.67595472, 0.67778121],\n",
       "       [6.        , 0.6801133 , 0.66487197, 0.69150428, 0.65374872],\n",
       "       [7.        , 0.70667416, 0.7085282 , 0.69420828, 0.70249144],\n",
       "       [8.        , 0.73980919, 0.75675064, 0.76383836, 0.75136847],\n",
       "       [9.        , 0.72388771, 0.72049259, 0.72024188, 0.72387412]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTIAL_STACKING = [\"kfr\", \"kpr\", \"ktmk\", \"ktr\", \"lfr\", \"lpr\", \"ltmk\", \"rep_bert\", \"xlnet_rep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for clf in PARTIAL_STACKING:\n",
    "    scores = []\n",
    "    for fold in np.arange(10):\n",
    "        y = np.load(f\"/home/welton/data/datasets/labels/split_10/webkb/{fold}/test.npy\")\n",
    "        loader = np.load(f\"/home/welton/data/clfs_output/split_10/webkb/10_folds/{clf}/{fold}/test.npz\")\n",
    "        preds = loader[\"X_test\"].argmax(axis=1)\n",
    "        scores.append(f1_score(y, preds, average=\"macro\"))\n",
    "    data.append([clf, np.mean(scores)])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_calib = []\n",
    "for clf in PARTIAL_STACKING:\n",
    "    scores = []\n",
    "    for fold in np.arange(10):\n",
    "        y = np.load(f\"/home/welton/data/datasets/labels/split_10/webkb/{fold}/test.npy\")\n",
    "        loader = np.load(f\"/home/welton/data/calibrated_probabilities/split_10/webkb/10_folds/{clf}/{fold}/test.npz\")\n",
    "        preds = loader[\"X_test\"].argmax(axis=1)\n",
    "        scores.append(f1_score(y, preds, average=\"macro\"))\n",
    "    data_calib.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLFs</th>\n",
       "      <th>Macro/NotCalib/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kfr</td>\n",
       "      <td>0.691658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kpr</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ktmk</td>\n",
       "      <td>0.647207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ktr</td>\n",
       "      <td>0.587643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lfr</td>\n",
       "      <td>0.682471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lpr</td>\n",
       "      <td>0.586632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ltmk</td>\n",
       "      <td>0.661907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rep_bert</td>\n",
       "      <td>0.828855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xlnet_rep</td>\n",
       "      <td>0.805402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CLFs  Macro/NotCalib/\n",
       "0        kfr         0.691658\n",
       "1        kpr         0.592531\n",
       "2       ktmk         0.647207\n",
       "3        ktr         0.587643\n",
       "4        lfr         0.682471\n",
       "5        lpr         0.586632\n",
       "6       ltmk         0.661907\n",
       "7   rep_bert         0.828855\n",
       "8  xlnet_rep         0.805402"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"CLFs\", \"Macro/NotCalib/\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Macro/Calib\"] = data_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.16575414, 69.02674312],\n",
       "       [59.25308489, 61.53338198],\n",
       "       [64.72074904, 65.32542604],\n",
       "       [58.76427235, 61.77397008],\n",
       "       [68.24707737, 65.9383586 ],\n",
       "       [58.66324212, 58.52594842],\n",
       "       [66.19068114, 59.4812232 ],\n",
       "       [82.88549204, 83.17521365],\n",
       "       [80.54021559, 80.54021559]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"CLFs\"]).values * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/welton/data/datasets/data/mini_20ng/texts.txt\", 'r') as fd:\n",
    "    sents = fd.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/welton/data/datasets/data/mini_20ng/score.txt\", 'r') as fd:\n",
    "    labes_list = fd.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labes_list.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([int (l) for l in labes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(strip_accents='unicode', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.fit_transform(sents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23845)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_pickle(\"/home/welton/data/datasets/data/mini_20ng/splits/split_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idxs</th>\n",
       "      <th>test_idxs</th>\n",
       "      <th>fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[165, 182, 186, 187, 188, 189, 190, 191, 194, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[165, 182, 186, 187, 188, 189, 190, 191, 194, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[372, 377, 382, 383, 385, 388, 389, 391, 392, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[574, 575, 576, 579, 581, 585, 586, 590, 591, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[765, 767, 769, 771, 773, 774, 775, 777, 778, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[969, 972, 976, 977, 978, 981, 982, 983, 984, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1152, 1155, 1156, 1157, 1158, 1160, 1162, 116...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1357, 1359, 1364, 1367, 1371, 1373, 1374, 137...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1577, 1578, 1582, 1587, 1590, 1591, 1592, 159...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1741, 1746, 1751, 1753, 1757, 1758, 1763, 177...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train_idxs  \\\n",
       "0  [165, 182, 186, 187, 188, 189, 190, 191, 194, ...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "5  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "6  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "7  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "8  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "9  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                           test_idxs  fold_id  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        0  \n",
       "1  [165, 182, 186, 187, 188, 189, 190, 191, 194, ...        1  \n",
       "2  [372, 377, 382, 383, 385, 388, 389, 391, 392, ...        2  \n",
       "3  [574, 575, 576, 579, 581, 585, 586, 590, 591, ...        3  \n",
       "4  [765, 767, 769, 771, 773, 774, 775, 777, 778, ...        4  \n",
       "5  [969, 972, 976, 977, 978, 981, 982, 983, 984, ...        5  \n",
       "6  [1152, 1155, 1156, 1157, 1158, 1160, 1162, 116...        6  \n",
       "7  [1357, 1359, 1364, 1367, 1371, 1373, 1374, 137...        7  \n",
       "8  [1577, 1578, 1582, 1587, 1590, 1591, 1592, 159...        8  \n",
       "9  [1741, 1746, 1751, 1753, 1757, 1758, 1763, 177...        9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(X_all, y_all, sp, fold, train_test_val):\n",
    "    idxs = sp.iloc[fold][f\"{train_test_val}_idxs\"]\n",
    "    x, y = X_all[idxs], y_all[idxs]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = \"/home/welton/data/representations/mini_20ng/10_folds/tr\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "labels_dir = \"/home/welton/data/datasets/labels/split_10_with_val/mini_20ng\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for fold in np.arange(10):\n",
    "    \n",
    "    X_train, y_train = get_xy(X, labels, sp, fold, \"train\")\n",
    "    os.makedirs(f\"{output_dir}/{fold}\", exist_ok=True)\n",
    "    np.savez(f\"{output_dir}/{fold}/train.npz\", X_train=X_train, y_train=y_train)\n",
    "    \n",
    "    X_test, y_test = get_xy(X, labels, sp, fold, \"test\")\n",
    "    np.savez(f\"{output_dir}/{fold}/test.npz\", X_test=X_test, y_test=y_test)\n",
    "\n",
    "    os.makedirs(f\"{labels_dir}/{fold}\", exist_ok=True)\n",
    "    np.save(f\"{labels_dir}/{fold}/test.npy\", y_test)\n",
    "    np.save(f\"{labels_dir}/{fold}/train.npy\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = np.load(\"/home/welton/data/representations/20ng/10_folds/tr/0/train.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_pickle(\"/home/welton/data/datasets/data/20ng/splits/split_10_with_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<13563x24304 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1010258 stored elements in Compressed Sparse Row format>,\n",
       " <3391x24304 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 249329 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(loader[\"X_train\"].tolist(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(<16954x24304 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1259587 stored elements in Compressed Sparse Row format>,\n",
       "       dtype=object),\n",
       " <16954x24304 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1259587 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader[\"X_train\"], loader[\"X_train\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"webkb\", \"acm\", \"reut\", \"20ng\"]:\n",
    "    sp = pd.read_pickle(f\"/home/welton/data/datasets/data/{dataset}/splits/split_10.pkl\")\n",
    "    for fold in np.arange(10):\n",
    "        x = np.array(sp.iloc[fold][\"train_idxs\"]).argsort()\n",
    "        print(np.unique(x == np.arange(x.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 3), (120,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.load(\"/home/welton/data/normal_probas/split_10/mini_20ng/10_folds/ktr/0/0/eval.npz\")\n",
    "L[\"X_eval\"].shape, L[\"y_eval\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 3), (600,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.load(\"/home/welton/data/normal_probas/split_10/mini_20ng/10_folds/ktr/0/0/test.npz\")\n",
    "L[\"X_test\"].shape, L[\"y_test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mvstack([])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "np.vstack([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
