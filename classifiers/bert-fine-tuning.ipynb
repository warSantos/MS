{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"07179042-e81a-4db0-ba49-1c70c8bdebb8","_uuid":"f98460c3-4ffa-490e-8cc1-9eba62d39652","collapsed":false,"execution":{"iopub.execute_input":"2022-10-09T20:19:26.586557Z","iopub.status.busy":"2022-10-09T20:19:26.586191Z","iopub.status.idle":"2022-10-09T20:19:27.729815Z","shell.execute_reply":"2022-10-09T20:19:27.728878Z","shell.execute_reply.started":"2022-10-09T20:19:26.586464Z"},"id":"06NGygawxM62","jupyter":{"outputs_hidden":false},"outputId":"243ff742-c734-41e8-b143-23d8592ae348","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Oct 14 18:18:09 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ...  On   | 00000000:0B:00.0 Off |                  N/A |\n","|  0%   46C    P8    14W / 215W |     14MiB /  8192MiB |      3%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      2322      G   /usr/lib/xorg/Xorg                  8MiB |\n","|    0   N/A  N/A      3063      G   /usr/bin/gnome-shell                3MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi ## Verificar placa de vídeo disponível no momento da execução"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"0a9bdc04-34d2-417b-ab83-c7b166f6be67","_uuid":"9b740d07-3971-4e1b-a62a-9726e5a3ccbe","collapsed":false,"execution":{"iopub.execute_input":"2022-10-09T20:12:12.879154Z","iopub.status.busy":"2022-10-09T20:12:12.878337Z","iopub.status.idle":"2022-10-09T20:12:12.886348Z","shell.execute_reply":"2022-10-09T20:12:12.885454Z","shell.execute_reply.started":"2022-10-09T20:12:12.879114Z"},"id":"r2q_RzOAxlbj","jupyter":{"outputs_hidden":false},"outputId":"aa523e30-9538-4cff-db4c-9394c4c0df67","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/welton/project/.env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","2022-10-14 18:18:11.204300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-14 18:18:11.347968: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-14 18:18:11.938871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2022-10-14 18:18:11.938931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2022-10-14 18:18:11.938937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["# imports\n","import io\n","import os\n","import pickle\n","import random\n","import jsonlines\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","\n","import torch\n","from torch.nn.functional import softmax\n","from torch.utils import data # trabalhar com dados iterados\n","from transformers import BertModel, BertTokenizer, AutoTokenizer\n","from datasets import load_metric\n","from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from transformers import AutoModelForSequenceClassification\n","from transformers import get_scheduler\n","from tqdm.auto import tqdm\n","\n","import timeit  # calcular metrica de tempo"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def get_doc_by_id(X, idxs):\n","\n","    docs = []\n","    for idx in idxs:\n","        docs.append(X[idx])\n","    return docs\n","\n","def data_process(dataset, fold, fast_test=False, sample_size=100):\n","\n","    split_settings = pd.read_pickle(\n","        f\"/home/welton/data/datasets/data/{dataset}/splits/split_10_with_val.pkl\")\n","    with io.open(f\"/home/welton/data/datasets/data/{dataset}/texts.txt\", newline='\\n', errors='ignore') as read:\n","        X = []\n","        for row in read:\n","            X.append(row.strip())\n","\n","    labels = []\n","    with open(f\"/home/welton/data/datasets/data/{dataset}/score.txt\") as fd:\n","        for line in fd:\n","            labels.append(int(line.strip()))\n","    labels = np.array(labels)\n","\n","    # Ajustando labels.\n","    labels[labels == -1] = 0\n","    if np.min(labels == 1):\n","        labels = labels - 1\n","\n","    sp_set = split_settings[split_settings.fold_id == fold]\n","\n","    X_train = get_doc_by_id(X, sp_set.train_idxs.tolist()[0])\n","    X_test = get_doc_by_id(X, sp_set.test_idxs.tolist()[0])\n","    X_val = get_doc_by_id(X, sp_set.val_idxs.tolist()[0])\n","\n","    y_train = labels[sp_set.train_idxs.iloc[0]]\n","    y_test = labels[sp_set.test_idxs.iloc[0]]\n","    y_val = labels[sp_set.val_idxs.iloc[0]]\n","\n","    if fast_test == True:\n","\n","        ss = min(sample_size, len(X_val))\n","        ids = np.arange(ss)\n","        size_s = ss - 1\n","        random_idxs = np.random.choice(ids, size_s, replace=False)\n","        X_train = get_doc_by_id(X_train, random_idxs)\n","        X_test = get_doc_by_id(X_test, random_idxs)\n","        X_val = get_doc_by_id(X_val, random_idxs)\n","\n","        y_train = y_train[random_idxs]\n","        y_test = y_test[random_idxs]\n","        y_val = y_val[random_idxs]\n","\n","    return X_train, X_test, X_val, y_train, y_test, y_val, split_settings\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T20:17:37.928929Z","iopub.status.busy":"2022-10-09T20:17:37.928669Z","iopub.status.idle":"2022-10-09T20:17:37.962603Z","shell.execute_reply":"2022-10-09T20:17:37.961530Z","shell.execute_reply.started":"2022-10-09T20:17:37.928897Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx])\n","                for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","\n","class BERT():\n","\n","    def __init__(\n","        self,\n","        batch_size: int = 8,\n","        limit_k: int = 20,\n","        max_epochs: int = 5,\n","        lr: float = 5e-5,\n","        max_length: int = 256,\n","        limit_patient: int = 3,\n","        model_path: str = \"bert-base-uncased\",\n","        padding: bool = True,\n","        truncation: bool = True,\n","        seed: int = 42\n","    ):\n","        self.batch_size = batch_size\n","        self.limit_k = limit_k\n","        self.max_epochs = max_epochs\n","        self.lr = lr\n","        self.max_length = max_length\n","        self.limit_patient = limit_patient\n","        self.model_path = model_path\n","        self.padding = padding\n","        self.truncation = truncation\n","        self.seed = seed\n","\n","    def encode_data(self, X_train, X_test, X_val, y_train, y_test, y_val):\n","\n","        # Codifica o texto.\n","        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","        train_encodings = tokenizer(X_train, max_length=self.max_length,\n","                                    return_tensors=\"pt\",  padding=self.padding, truncation=self.truncation)\n","        val_encodings = tokenizer(X_val, max_length=self.max_length,\n","                                  return_tensors=\"pt\",  padding=self.padding, truncation=self.truncation)\n","        test_encodings = tokenizer(X_test, max_length=self.max_length,\n","                                   return_tensors=\"pt\",  padding=self.padding, truncation=self.truncation)\n","\n","        # Converte o dado para o formato DataLoader.\n","        train_dataset = CustomDataset(train_encodings, y_train)\n","        val_dataset = CustomDataset(val_encodings, y_val)\n","        test_dataset = CustomDataset(test_encodings, y_test)\n","\n","        # Coloca o processo em batch\n","        train_dataloader = DataLoader(\n","            train_dataset, shuffle=True, batch_size=self.batch_size, worker_init_fn=self.seed)\n","        eval_dataloader = DataLoader(\n","            val_dataset, batch_size=self.batch_size, worker_init_fn=self.seed)\n","        test_dataloader = DataLoader(\n","            test_dataset, batch_size=self.batch_size, worker_init_fn=self.seed)\n","\n","        return train_dataloader, eval_dataloader, test_dataloader\n","\n","    def fit_predict(self, X_train, X_test, X_val, y_train, y_test, y_val):\n","\n","        # Preparado dataloaders.\n","        train_dataloader, eval_dataloader, test_dataloader = self.encode_data(\n","            X_train, X_test, X_val, y_train, y_test, y_val)\n","        num_labels = np.unique(np.hstack([y_train, y_test, y_val])).shape[0]\n","\n","        \"\"\"\n","        model = torch.load(\"/home/welton/data/clfs_output/split_10/webkb/10_folds/rep_bert_bkp/0/model\")\n","        device = torch.device(\n","                \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","        model.to(device)\n","        \"\"\"\n","        \n","        # Define o modelo de classificação\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            self.model_path, num_labels=num_labels)\n","        optimizer = AdamW(model.parameters(), lr=self.lr)\n","        num_training_steps = self.max_epochs * len(train_dataloader)\n","        lr_scheduler = get_scheduler(\n","            \"linear\",\n","            optimizer=optimizer,\n","            num_warmup_steps=0,\n","            num_training_steps=num_training_steps\n","        )\n","\n","        # Coloca para o processamento ser feito na GPU\n","        device = torch.device(\n","            \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","        model.to(device)\n","\n","        # Treina o modelo\n","        progress_bar = tqdm(range(num_training_steps))\n","        cont_patient = 0\n","        min_loss_eval = 10000\n","\n","        # Para cada época.\n","        for epoch in range(self.max_epochs):\n","            model.train()\n","            # Para cada batch.\n","            for batch in train_dataloader:\n","                progress_bar.update(1)\n","                batch = {k: v.to(device) for k, v in batch.items()}\n","                outputs = model(**batch)\n","                loss = outputs.loss\n","                loss.backward()\n","                optimizer.step()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","\n","            # validação\n","            y_pred_list = []\n","            y_true_list = []\n","\n","            model.eval()  # define para não atualizar pesos na validação\n","            for batch in eval_dataloader:\n","                batch = {k: v.to(device) for k, v in batch.items()}\n","\n","                with torch.no_grad():  # define para não atualizar pesos na validação\n","                    outputs = model(**batch)\n","\n","                loss = outputs.loss\n","                predictions = torch.argmax(outputs.logits, dim=-1)\n","                y_pred_list.append(predictions.tolist())\n","                y_true_list.append(list(batch[\"labels\"].tolist()))\n","\n","            y_pred_batch = []\n","            y_true_batch = []\n","\n","            for y_batch in y_pred_list:  # y_batchs\n","                for y_doc in y_batch:\n","                    y_pred_batch.append(y_doc)\n","\n","            for y_batch in y_true_list:  # y_batchs\n","                for y_doc in y_batch:\n","                    y_true_batch.append(y_doc)\n","\n","            # armazena as metricas a partir das predicoes\n","            loss_eval_atual = loss.item()\n","\n","            # parar de treinar se não houver melhoria\n","            if loss_eval_atual < min_loss_eval:\n","                cont_patient = 0\n","                min_loss_eval = loss_eval_atual\n","            else:\n","                cont_patient += 1\n","\n","            if cont_patient >= self.limit_patient:\n","                break\n","\n","        # ---------- TESTE ---------- #\n","        probs = []\n","        model.eval()\n","        for batch in test_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            with torch.no_grad():\n","                outputs = model(**batch)\n","                norm = softmax(outputs.logits, dim=-1).tolist()\n","                probs.append(norm)\n","\n","        probs = np.vstack(probs)\n","        return probs, model\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_train_probas(X, y, base_path, n_splits=4):\n","\n","    # Train probas.\n","    sfk = StratifiedKFold(n_splits=n_splits)\n","    sfk.get_n_splits(X, y)\n","    alig_idx = np.arange(y.shape[0])\n","    idx_list = []\n","    probas = []\n","    for fold, (train_index, test_index) in enumerate(sfk.split(X, y)):\n","\n","        Xt = get_doc_by_id(X, train_index)\n","        Yt = y[train_index]\n","\n","        X_train, X_val, y_train, y_val = train_test_split(\n","            Xt, Yt, test_size=0.1)\n","\n","        X_test = get_doc_by_id(X, test_index)\n","        y_test = y[test_index]\n","\n","        idx_list.append(alig_idx[test_index])\n","\n","        # Applying oversampling when it is needed.\n","        for c in set(y_test) - set(y_train):\n","\n","            sintetic = np.zeros(X_train.shape[1])\n","            X_train = np.vstack([X_train, sintetic])\n","            y_train = np.hstack([y_train, [c]])\n","\n","        bert_model = BERT()\n","        p, _ = bert_model.fit_predict(\n","            X_train, X_test, X_val, y_train, y_test, y_val)\n","        probas.append(p)\n","        scoring = {}\n","        y_pred = p.argmax(axis=1)\n","        scoring[\"macro\"] = f1_score(y_test, y_pred, average=\"macro\")\n","        scoring[\"micro\"] = f1_score(y_test, y_pred, average=\"micro\")\n","        print(\n","            f\"\\t\\tFOLD {fold} - Macro: {scoring['macro']} - Micro {scoring['micro']}\")\n","        torch.cuda.empty_cache()\n","\n","    probas = np.vstack(probas)\n","    sorted_idxs = np.hstack(idx_list).argsort()\n","    probas = probas[sorted_idxs]\n","    probas_path = f\"{base_path}/train\"\n","    np.savez(probas_path, X_train=probas)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T20:01:02.692672Z","iopub.status.busy":"2022-10-09T20:01:02.692174Z","iopub.status.idle":"2022-10-09T20:01:02.703397Z","shell.execute_reply":"2022-10-09T20:01:02.702715Z","shell.execute_reply.started":"2022-10-09T20:01:02.692638Z"},"trusted":true},"outputs":[],"source":["SEED = 42\n","\n","# Hiperparametros do modelo\n","fast_test = False\n","sample_size = 400\n","\n","#hyper-parameters\n","batch_size = 8\n","limit_k = 20\n","max_epochs = 5\n","lr = 5e-5\n","max_length = 256\n","limit_patient = 3\n","\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","np.random.seed(seed=SEED)\n","\n","datasets = ['webkb']\n","\n","# Trian probas parameters.\n","\n","train_n_splits = 4"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T20:01:02.704950Z","iopub.status.busy":"2022-10-09T20:01:02.704648Z","iopub.status.idle":"2022-10-09T20:01:06.901049Z","shell.execute_reply":"2022-10-09T20:01:06.899913Z","shell.execute_reply.started":"2022-10-09T20:01:02.704916Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WEBKB - FOLD: 0\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/home/welton/project/.env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","  0%|          | 0/4150 [00:00<?, ?it/s]/tmp/ipykernel_3997782/3070078370.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx])\n","  2%|▏         | 79/4150 [00:14<12:35,  5.39it/s]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [7], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m bert_model \u001b[39m=\u001b[39m BERT(\n\u001b[1;32m     14\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     15\u001b[0m     limit_k\u001b[39m=\u001b[39mlimit_k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     seed\u001b[39m=\u001b[39mSEED)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Treinando e realizando predições com o modelo.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m probs, model \u001b[39m=\u001b[39m bert_model\u001b[39m.\u001b[39;49mfit_predict(\n\u001b[1;32m     25\u001b[0m     X_train, X_test, X_val, y_train, y_test, y_val)\n\u001b[1;32m     26\u001b[0m test_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase_path\u001b[39m}\u001b[39;00m\u001b[39m/test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m np\u001b[39m.\u001b[39msavez(test_path, X_test\u001b[39m=\u001b[39mprobs)\n","Cell \u001b[0;32mIn [4], line 112\u001b[0m, in \u001b[0;36mBERT.fit_predict\u001b[0;34m(self, X_train, X_test, X_val, y_train, y_test, y_val)\u001b[0m\n\u001b[1;32m    110\u001b[0m progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m    111\u001b[0m batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 112\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n\u001b[1;32m    113\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m    114\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1560\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1560\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1561\u001b[0m     input_ids,\n\u001b[1;32m   1562\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1563\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1564\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1565\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1566\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1567\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1568\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1569\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1570\u001b[0m )\n\u001b[1;32m   1572\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:611\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    602\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    603\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    604\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    612\u001b[0m         hidden_states,\n\u001b[1;32m    613\u001b[0m         attention_mask,\n\u001b[1;32m    614\u001b[0m         layer_head_mask,\n\u001b[1;32m    615\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    616\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    617\u001b[0m         past_key_value,\n\u001b[1;32m    618\u001b[0m         output_attentions,\n\u001b[1;32m    619\u001b[0m     )\n\u001b[1;32m    621\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[0;32m--> 436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:387\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    386\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 387\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    388\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[1;32m    389\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[0;32m~/project/.env/lib/python3.8/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for dataset in datasets:\n","    for fold in np.arange(10):\n","        print(f\"{dataset.upper()} - FOLD: {fold}\")\n","\n","        base_path = f\"/home/welton/data/clfs_output/split_10/{dataset}/10_folds/rep_bert/{fold}\"\n","        os.makedirs(base_path, exist_ok=True)\n","\n","        # Separando o dataset.\n","        X_train, X_test, X_val, y_train, y_test, y_val, sp_settings = data_process(\n","            dataset, fold, fast_test=fast_test, sample_size=sample_size)\n","        # Configurando os parâmetros do modelo.\n","\n","        bert_model = BERT(\n","            batch_size=batch_size,\n","            limit_k=limit_k,\n","            max_epochs=max_epochs,\n","            lr=lr,\n","            max_length=max_length,\n","            limit_patient=limit_patient,\n","            padding=True,\n","            truncation=True,\n","            seed=SEED)\n","        # Treinando e realizando predições com o modelo.\n","        probs, model = bert_model.fit_predict(\n","            X_train, X_test, X_val, y_train, y_test, y_val)\n","        test_path = f\"{base_path}/test\"\n","        np.savez(test_path, X_test=probs)\n","        model_path = f\"{base_path}/model\"\n","        torch.save(model, model_path)\n","        y_pred = probs.argmax(axis=1)\n","        print(f\"Macro: {f1_score(y_test, y_pred, average='macro')}\")\n","        print(f\"Macro: {f1_score(y_test, y_pred, average='micro')}\")\n","        torch.cuda.empty_cache()\n","\n","        #get_train_probas(X_train + X_test + X_val, np.hstack([y_train, y_test, y_val]), base_path)\n","        sort = np.array(sp_settings.iloc[fold][\"train_idxs\"] + sp_settings.iloc[fold][\"val_idxs\"]).argsort()\n","        get_train_probas(get_doc_by_id(X_train + X_val, sort), np.hstack([y_train, y_val])[sort], base_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('.env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"f3135864b85fc339145ed731976b9bcbd775d49eba38ad5ba8da470ad91643c0"}}},"nbformat":4,"nbformat_minor":4}
